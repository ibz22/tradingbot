import alpaca_trade_api as tradeapi
import ccxt
import pandas as pd
import numpy as np
import os
from datetime import datetime, timedelta
import logging
import warnings
import joblib
import time
import yaml
import json
import smtplib
import requests
import unittest
from typing import Dict, Tuple, List, Optional, Union
from dataclasses import dataclass, field
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from pathlib import Path
import asyncio
import aiohttp
from concurrent.futures import ThreadPoolExecutor
import threading
from contextlib import asynccontextmanager
import sys
import argparse
from functools import wraps

warnings.filterwarnings('ignore')

# =============================================================================
# DEPENDENCY MANAGEMENT & FALLBACKS
# =============================================================================

# Load environment variables from .env file
try:
    from dotenv import load_dotenv
    load_dotenv()
    logging.info("‚úÖ .env file loaded successfully")
except ImportError:
    logging.warning("python-dotenv not installed. Using system environment variables.")

# Technical analysis imports with fallbacks
try:
    import talib
    TALIB_AVAILABLE = True
except ImportError:
    try:
        import pandas_ta as ta
        TALIB_AVAILABLE = False
        logging.warning("talib not available, using pandas_ta as fallback")
    except ImportError:
        logging.error("‚ùå Neither talib nor pandas_ta available. Please install one of them via: "
                      "'pip install ta-lib' or 'pip install pandas_ta'")
        raise ImportError("Technical analysis library required")

# ML imports with fallbacks
try:
    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
    from sklearn.preprocessing import StandardScaler, RobustScaler
    from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, cross_val_score
    from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score
    from sklearn.feature_selection import SelectKBest, f_classif
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False
    logging.warning("‚ùå scikit-learn not available, ML strategy disabled. Please install with 'pip install scikit-learn'")

# =============================================================================
# GLOBAL CONFIGURATION
# =============================================================================

def setup_logging(log_level: str = "INFO", log_file: str = "trading_bot.log"):
    """Setup enhanced logging with rotation and better formatting"""
    from logging.handlers import RotatingFileHandler
    
    Path("logs").mkdir(exist_ok=True)
    
    class ColoredFormatter(logging.Formatter):
        COLORS = {
            'DEBUG': '\033[36m',     # Cyan
            'INFO': '\033[32m',      # Green
            'WARNING': '\033[33m',   # Yellow
            'ERROR': '\033[31m',     # Red
            'CRITICAL': '\033[35m',  # Magenta
            'RESET': '\033[0m'       # Reset
        }
        
        def format(self, record):
            color = self.COLORS.get(record.levelname, self.COLORS['RESET'])
            record.levelname = f"{color}{record.levelname}{self.COLORS['RESET']}"
            return super().format(record)
    
    file_handler = RotatingFileHandler(
        f"logs/{log_file}", 
        maxBytes=10*1024*1024, 
        backupCount=5,
        encoding='utf-8'
    )
    file_formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'
    )
    file_handler.setFormatter(file_formatter)
    
    console_handler = logging.StreamHandler()
    console_formatter = ColoredFormatter(
        '%(asctime)s - %(levelname)s - %(message)s'
    )
    console_handler.setFormatter(console_formatter)
    
    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        handlers=[file_handler, console_handler],
        force=True
    )

def print_startup_summary(args, config):
    """Prints a quick summary of the bot's configuration at startup."""
    logging.info("=" * 60)
    logging.info("üïå Enhanced Halal Trading Bot v2.2 - Startup Summary")
    logging.info(f"Mode: {'Live' if args.mode == 'live' else args.mode.title()}")
    logging.info(f"Dry Run: {'‚úÖ Enabled' if args.dry_run else '‚ùå Disabled'}")
    logging.info(f"Configuration File: {args.config}")
    logging.info(f"Logging Level: {logging.getLevelName(logging.getLogger().level)}")
    logging.info("-" * 60)
    logging.info(f"Alpaca Paper Trading: {'‚úÖ Enabled' if config.alpaca_paper_trading else '‚ùå Disabled'}")
    logging.info(f"Binance Testnet: {'‚úÖ Enabled' if config.binance_testnet else '‚ùå Disabled'}")
    logging.info(f"ML Strategy: {'‚úÖ Enabled' if ML_AVAILABLE else '‚ùå Disabled'}")
    logging.info(f"Notifications: {'‚úÖ Enabled' if config.enable_notifications else '‚ùå Disabled'}")
    logging.info(f"Concurrent Assets: {config.max_concurrent_assets}")
    logging.info("=" * 60)

# =============================================================================
# ENHANCED DATA STRUCTURES
# =============================================================================

@dataclass
class TradingConfig:
    """Enhanced configuration with validation and type hints"""
    
    # Risk Management
    max_portfolio_risk: float = 0.02
    max_position_risk: float = 0.01
    max_position_pct: float = 0.1
    
    # Trading Parameters
    confidence_threshold: float = 0.4
    rebalance_frequency: str = '1h'
    min_data_points: int = 50
    
    # API Settings
    alpaca_paper_trading: bool = True
    binance_testnet: bool = True
    max_retries: int = 3
    retry_delay: float = 5.0
    
    # Strategy Weights
    default_strategy_weights: Dict[str, float] = field(default_factory=lambda: {
        'momentum_breakout': 0.4,
        'mean_reversion': 0.3,
        'ml_strategy': 0.3
    })
    
    # Assets
    stock_universe: List[str] = field(default_factory=lambda: [
        'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', 'NVDA', 'BRK.B', 'JNJ', 'V'
    ])
    crypto_universe: List[str] = field(default_factory=lambda: [
        'BTC/USDT', 'ETH/USDT', 'SOL/USDT', 'ADA/USDT', 'DOT/USDT', 'AVAX/USDT', 'ALGO/USDT'
    ])
    
    # Notification Settings
    enable_notifications: bool = True
    notification_channels: List[str] = field(default_factory=lambda: ['telegram', 'email'])
    
    # ML Settings
    ml_retrain_hours: int = 24
    ml_min_samples: int = 100
    ml_feature_selection: bool = True
    ml_ensemble_models: bool = True
    
    # Performance Settings
    max_concurrent_assets: int = 10
    data_cache_hours: int = 1
    enable_performance_monitoring: bool = True
    
    def __post_init__(self):
        """Validate configuration parameters"""
        self._validate_risk_parameters()
        self._validate_strategy_weights()
        self._validate_trading_parameters()
        self._validate_ml_parameters()

    def _validate_risk_parameters(self):
        """Validate risk management parameters"""
        if not (0 < self.max_portfolio_risk <= 1):
            raise ValueError(f"max_portfolio_risk must be between 0 and 1, got {self.max_portfolio_risk}")
        if not (0 < self.max_position_risk <= 1):
            raise ValueError(f"max_position_risk must be between 0 and 1, got {self.max_position_risk}")
        if not (0 < self.max_position_pct <= 1):
            raise ValueError(f"max_position_pct must be between 0 and 1, got {self.max_position_pct}")
        if self.max_position_risk > self.max_portfolio_risk:
            raise ValueError("max_position_risk cannot exceed max_portfolio_risk")
    
    def _validate_strategy_weights(self):
        """Validate strategy weights sum to approximately 1"""
        total_weight = sum(self.default_strategy_weights.values())
        if not (0.99 <= total_weight <= 1.01):
            raise ValueError(f"Strategy weights must sum to 1, got {total_weight}")
        
        for strategy, weight in self.default_strategy_weights.items():
            if not (0 <= weight <= 1):
                raise ValueError(f"Strategy weight for {strategy} must be between 0 and 1, got {weight}")
    
    def _validate_trading_parameters(self):
        """Validate trading parameters"""
        if not (0 < self.confidence_threshold <= 1):
            raise ValueError(f"confidence_threshold must be between 0 and 1, got {self.confidence_threshold}")
        if self.min_data_points < 20:
            raise ValueError(f"min_data_points must be at least 20, got {self.min_data_points}")
        if self.max_retries < 1:
            raise ValueError(f"max_retries must be at least 1, got {self.max_retries}")
        if self.retry_delay < 0:
            raise ValueError(f"retry_delay must be non-negative, got {self.retry_delay}")
    
    def _validate_ml_parameters(self):
        """Validate ML parameters"""
        if self.ml_min_samples < 50:
            raise ValueError(f"ml_min_samples must be at least 50, got {self.ml_min_samples}")
        if self.ml_retrain_hours < 1:
            raise ValueError(f"ml_retrain_hours must be at least 1, got {self.ml_retrain_hours}")
        if self.max_concurrent_assets < 1:
            raise ValueError(f"max_concurrent_assets must be at least 1, got {self.max_concurrent_assets}")

    @classmethod
    def from_yaml(cls, file_path: str = "config.yaml"):
        """Load configuration from YAML file with validation"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                config_dict = yaml.safe_load(f)
            instance = cls(**config_dict)
            logging.info(f"‚úÖ Configuration loaded from {file_path}")
            return instance
        except FileNotFoundError:
            logging.warning(f"Config file {file_path} not found, creating default configuration")
            instance = cls()
            instance.save_to_yaml(file_path)
            return instance
        except yaml.YAMLError as e:
            logging.error(f"YAML parsing error in {file_path}: {e}")
            return cls()
        except Exception as e:
            logging.error(f"Error loading config from {file_path}: {e}")
            return cls()

    def save_to_yaml(self, file_path: str = "config.yaml"):
        """Save configuration to YAML file"""
        try:
            config_dict = {k: v for k, v in self.__dict__.items() if not k.startswith('_')}
            with open(file_path, 'w', encoding='utf-8') as f:
                yaml.dump(config_dict, f, default_flow_style=False, indent=2, sort_keys=True)
            logging.info(f"‚úÖ Configuration saved to {file_path}")
        except Exception as e:
            logging.error(f"Error saving config to {file_path}: {e}")

@dataclass
class TradeSignal:
    """Enhanced trade signal with metadata and validation"""
    action: str  # 'buy', 'sell', 'hold'
    confidence: float  # 0.0 to 1.0
    strategy: str
    price_target: Optional[float] = None
    stop_loss: Optional[float] = None
    timestamp: datetime = field(default_factory=datetime.now)
    risk_level: str = field(init=False)
    signal_strength: str = field(init=False)
    
    def __post_init__(self):
        # Validate inputs
        if self.action not in ['buy', 'sell', 'hold']:
            raise ValueError(f"Invalid action: {self.action}")
        if not (0.0 <= self.confidence <= 1.0):
            raise ValueError(f"Confidence must be between 0 and 1: {self.confidence}")
        
        # Calculate derived fields
        if self.confidence > 0.8:
            self.risk_level = "Low"
            self.signal_strength = "Strong"
        elif self.confidence > 0.6:
            self.risk_level = "Medium" 
            self.signal_strength = "Moderate"
        elif self.confidence > 0.4:
            self.risk_level = "High"
            self.signal_strength = "Weak"
        else:
            self.risk_level = "Very High"
            self.signal_strength = "Very Weak"

@dataclass
class AssetConfig:
    """Enhanced asset-specific configuration with validation"""
    symbol: str
    is_crypto: bool
    precision: int = 2
    min_qty: float = 1.0
    max_position_pct: float = 0.1
    volatility_threshold: float = 0.02
    strategy_weights: Optional[Dict[str, float]] = None
    halal_status: Optional[str] = None  # 'approved', 'pending', 'rejected'
    last_screened: Optional[datetime] = None
    compliance_score: float = 0.0
    
    def __post_init__(self):
        # Validate parameters
        if self.precision < 0:
            raise ValueError(f"Precision cannot be negative: {self.precision}")
        if self.min_qty <= 0:
            raise ValueError(f"Minimum quantity must be positive: {self.min_qty}")
        if not (0 < self.max_position_pct <= 1):
            raise ValueError(f"Max position percentage must be between 0 and 1: {self.max_position_pct}")
        
        # Set default strategy weights if not provided
        if self.strategy_weights is None:
            if self.is_crypto:
                self.strategy_weights = {
                    'momentum_breakout': 0.5,
                    'ml_strategy': 0.3,
                    'mean_reversion': 0.2
                }
            else:
                self.strategy_weights = {
                    'mean_reversion': 0.4,
                    'ml_strategy': 0.35,
                    'momentum_breakout': 0.25
                }

@dataclass
class TradeExecution:
    """Enhanced trade execution tracking with performance metrics"""
    symbol: str
    action: str
    quantity: float
    price: float
    timestamp: datetime
    order_id: Optional[str] = None
    status: str = "pending"  # pending, filled, rejected, cancelled
    fees: float = 0.0
    slippage: float = 0.0
    execution_time: float = 0.0  # Time to execute in seconds
    market_impact: float = 0.0   # Price impact of the trade
    
    def __post_init__(self):
        # Validate execution data
        if self.action not in ['buy', 'sell']:
            raise ValueError(f"Invalid trade action: {self.action}")
        if self.quantity <= 0:
            raise ValueError(f"Quantity must be positive: {self.quantity}")
        if self.price <= 0:
            raise ValueError(f"Price must be positive: {self.price}")
        if self.status not in ['pending', 'filled', 'rejected', 'cancelled']:
            raise ValueError(f"Invalid status: {self.status}")


# =============================================================================
# PLACEHOLDER CLASSES (Reference implementations)
# =============================================================================

# These are now correctly placed and defined before their use in the main bot class.
# The `run_live_trading` function will not throw an error because these classes
# are defined before the `main` function is called.

class EnhancedTradeExecutor:
    """Enhanced trade execution - use implementation from original code"""
    def __init__(self, connection_manager, config, is_dry_run: bool = False):
        self.connection_manager = connection_manager
        self.config = config
        self.trade_history = []
        self.is_dry_run = is_dry_run
    
    async def execute_trade(self, symbol, signal, position_size, is_crypto):
        if self.is_dry_run:
            logging.info(f"[DRY-RUN] Simulating trade: {signal.action.upper()} {position_size:.6f} {symbol}")
            return TradeExecution(
                symbol=symbol,
                action=signal.action,
                quantity=position_size,
                price=100.0, # Mock price
                timestamp=datetime.now(),
                status='filled',
                order_id='dry_run_123'
            )
        # Placeholder - use your original implementation for real trading
        logging.info(f"Executing trade: {signal.action.upper()} {position_size:.6f} {symbol}")
        return None

class EnhancedBacktestEngine:
    """Enhanced backtesting engine - use implementation from original code"""
    def __init__(self, initial_capital, config, strategies):
        self.initial_capital = initial_capital
        self.config = config
        self.strategies = strategies
    
    def run_backtest(self, symbol, df, is_crypto):
        # Placeholder - use your original implementation
        logging.info(f"Running backtest for {symbol}")
        return {
            'initial_capital': self.initial_capital,
            'final_equity': self.initial_capital * 1.15,
            'total_trades': 50,
            'performance_metrics': {
                'total_return': 0.15,
                'annualized_return': 0.25,
                'max_drawdown': 0.08,
                'sharpe_ratio': 1.5,
                'sortino_ratio': 2.0,
                'win_rate': 0.65,
                'profit_factor': 1.8
            }
        }


# =============================================================================
# CORE APPLICATION CLASSES
# =============================================================================

# Helper to run synchronous functions in an asynchronous context without blocking the event loop
def run_sync(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, func, *args, **kwargs)
    return wrapper

class ConnectionManager:
    """Enhanced API connection management with connection pooling and health checks"""
    
    def __init__(self, config: TradingConfig):
        self.config = config
        self.alpaca = None
        self.exchange = None
        self._connection_lock = threading.Lock()
        self._last_health_check = {}
        self._health_check_interval = 300  # 5 minutes
        self._session_pools = {}
        self._initialize_connections()
    
    def _initialize_connections(self):
        """Initialize API connections with enhanced error handling"""
        self._init_alpaca()
        self._init_binance()
        self._init_session_pools()

    def _init_alpaca(self):
        """Initialize Alpaca connection"""
        try:
            api_key = os.getenv('ALPACA_API_KEY')
            secret_key = os.getenv('ALPACA_SECRET_KEY')
            
            if not api_key or not secret_key:
                logging.warning("‚ùå Alpaca credentials not found in environment variables")
                return
            
            base_url = ('https://paper-api.alpaca.markets' 
                        if self.config.alpaca_paper_trading 
                        else 'https://api.alpaca.markets')
            
            self.alpaca = tradeapi.REST(
                api_key, 
                secret_key, 
                base_url, 
                api_version='v2'
            )
            
            # Test connection
            account = self.alpaca.get_account()
            logging.info(f"‚úÖ Alpaca API connected successfully (Account: {account.status})")
            
        except Exception as e:
            logging.error(f"‚ùå Failed to initialize Alpaca API: {e}")
            self.alpaca = None

    def _init_binance(self):
        """Initialize Binance connection"""
        try:
            api_key = os.getenv('BINANCE_API_KEY')
            secret_key = os.getenv('BINANCE_SECRET_KEY')
            
            if not api_key or not secret_key:
                logging.warning("‚ùå Binance credentials not found in environment variables")
                return
            
            self.exchange = ccxt.binance({
                'apiKey': api_key,
                'secret': secret_key,
                'enableRateLimit': True,
                'sandbox': self.config.binance_testnet,
                'timeout': 30000,  # 30 seconds
                'rateLimit': 100,  # Requests per second
            })
            
            # Test connection
            balance = self.exchange.fetch_balance()
            logging.info(f"‚úÖ Binance API connected successfully (Testnet: {self.config.binance_testnet})")
            
        except Exception as e:
            logging.error(f"‚ùå Failed to initialize Binance API: {e}")
            self.exchange = None
    
    def _init_session_pools(self):
        """Initialize HTTP session pools for external APIs"""
        try:
            import aiohttp
            self._session_pools['async'] = aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=30),
                connector=aiohttp.TCPConnector(limit=100, limit_per_host=30)
            )
            logging.info("‚úÖ HTTP session pools initialized")
        except ImportError:
            logging.warning("aiohttp not available, some features may be limited")

    async def execute_with_retry(self, func, *args, **kwargs):
        """Enhanced retry logic with exponential backoff and jitter"""
        last_exception = None
        base_delay = self.config.retry_delay
        
        for attempt in range(self.config.max_retries):
            try:
                if asyncio.iscoroutinefunction(func):
                    return await func(*args, **kwargs)
                else:
                    loop = asyncio.get_event_loop()
                    with ThreadPoolExecutor(max_workers=4) as executor:
                        return await loop.run_in_executor(executor, func, *args, **kwargs)
                        
            except Exception as e:
                last_exception = e
                
                if attempt == self.config.max_retries - 1:
                    logging.error(f"All {self.config.max_retries} retry attempts failed: {e}")
                    raise e
                
                delay = base_delay * (2 ** attempt) + np.random.uniform(0, 1)
                logging.warning(f"Attempt {attempt + 1} failed: {e}. Retrying in {delay:.2f}s...")
                await asyncio.sleep(delay)
        
        raise last_exception
    
    async def health_check(self) -> Dict[str, bool]:
        """Perform health checks on all connections"""
        current_time = time.time()
        health_status = {}
        
        if (current_time - self._last_health_check.get('timestamp', 0) < 
            self._health_check_interval):
            return self._last_health_check.get('status', {})
        
        # Alpaca health check
        try:
            if self.alpaca:
                account = await self.execute_with_retry(self.alpaca.get_account)
                health_status['alpaca'] = account.status == 'ACTIVE'
            else:
                health_status['alpaca'] = False
        except Exception as e:
            logging.warning(f"Alpaca health check failed: {e}")
            health_status['alpaca'] = False
        
        # Binance health check
        try:
            if self.exchange:
                server_time = await self.execute_with_retry(self.exchange.fetch_time)
                health_status['binance'] = abs(server_time - current_time * 1000) < 60000  # 1 minute tolerance
            else:
                health_status['binance'] = False
        except Exception as e:
            logging.warning(f"Binance health check failed: {e}")
            health_status['binance'] = False
        
        # Update cache
        self._last_health_check = {
            'timestamp': current_time,
            'status': health_status
        }
        
        return health_status
    
    async def close(self):
        """Clean up connections"""
        try:
            if 'async' in self._session_pools:
                await self._session_pools['async'].close()
            logging.info("‚úÖ Connection pools closed successfully")
        except Exception as e:
            logging.error(f"Error closing connections: {e}")

class NotificationManager:
    """Enhanced multi-channel notification system with rate limiting"""
    
    def __init__(self, config: TradingConfig):
        self.config = config
        self.telegram_bot_token = os.getenv('TELEGRAM_BOT_TOKEN')
        self.telegram_chat_id = os.getenv('TELEGRAM_CHAT_ID')
        self.email_config = {
            'smtp_server': os.getenv('SMTP_SERVER', 'smtp.gmail.com'),
            'smtp_port': int(os.getenv('SMTP_PORT', '587')),
            'email': os.getenv('NOTIFICATION_EMAIL'),
            'password': os.getenv('EMAIL_PASSWORD')
        }
        
        # Rate limiting
        self._notification_history = []
        self._max_notifications_per_hour = 20
        
        # Template system
        self._message_templates = {
            'trade_alert': self._trade_alert_template,
            'session_summary': self._session_summary_template,
            'error_alert': self._error_alert_template
        }
    
    async def send_trade_alert(self, signal: TradeSignal, symbol: str, price: float):
        """Send trade alert with rate limiting"""
        if not self.config.enable_notifications or not self._should_send_notification():
            return
        
        try:
            message = self._message_templates['trade_alert'](signal, symbol, price)
            await self._send_to_channels(message, 'trade_alert')
            
            # Log notification
            self._notification_history.append({
                'timestamp': datetime.now(),
                'type': 'trade_alert',
                'symbol': symbol,
                'action': signal.action
            })
            
            logging.info(f"üì¢ Trade alert sent: {signal.action.upper()} {symbol}")
            
        except Exception as e:
            logging.error(f"Failed to send trade alert: {e}")
    
    async def send_summary_report(self, report: str):
        """Send session summary report"""
        if not self.config.enable_notifications:
            return
        
        try:
            formatted_report = self._message_templates['session_summary'](report)
            await self._send_to_channels(formatted_report, 'session_summary')
            
            logging.info("üìä Session summary sent")
            
        except Exception as e:
            logging.error(f"Failed to send session summary: {e}")
    
    async def send_error_alert(self, error_msg: str, severity: str = 'medium'):
        """Send error alerts for critical issues"""
        if not self.config.enable_notifications or severity == 'low':
            return
        
        try:
            message = self._message_templates['error_alert'](error_msg, severity)
            await self._send_to_channels(message, 'error_alert')
            
            logging.warning(f"üö® Error alert sent: {severity}")
            
        except Exception as e:
            logging.error(f"Failed to send error alert: {e}")
    
    def _should_send_notification(self) -> bool:
        """Check rate limiting"""
        current_time = datetime.now()
        
        # Remove old notifications (older than 1 hour)
        self._notification_history = [
            notif for notif in self._notification_history
            if current_time - notif['timestamp'] < timedelta(hours=1)
        ]
        
        return len(self._notification_history) < self._max_notifications_per_hour
    
    async def _send_to_channels(self, message: str, msg_type: str):
        """Send message to configured channels"""
        tasks = []
        
        for channel in self.config.notification_channels:
            if channel == 'telegram' and self.telegram_bot_token:
                tasks.append(self._send_telegram(message))
            elif channel == 'email' and self.email_config['email']:
                subject = f"üïå Halal Trading Bot - {msg_type.replace('_', ' ').title()}"
                tasks.append(self._send_email(subject, message))
        
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)
    
    async def _send_telegram(self, message: str):
        """Send message via Telegram with async support"""
        try:
            url = f"https://api.telegram.org/bot{self.telegram_bot_token}/sendMessage"
            data = {
                'chat_id': self.telegram_chat_id,
                'text': message,
                'parse_mode': 'Markdown',
                'disable_web_page_preview': True
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(url, data=data, timeout=10) as response:
                    response.raise_for_status()
                    
        except Exception as e:
            logging.error(f"Telegram notification failed: {e}")
    
    async def _send_email(self, subject: str, message: str):
        """Send email notification with async support"""
        try:
            # Run email sending in thread pool to avoid blocking
            loop = asyncio.get_event_loop()
            with ThreadPoolExecutor(max_workers=2) as executor:
                await loop.run_in_executor(executor, self._send_email_sync, subject, message)
                
        except Exception as e:
            logging.error(f"Email notification failed: {e}")
    
    def _send_email_sync(self, subject: str, message: str):
        """Synchronous email sending"""
        try:
            msg = MIMEMultipart()
            msg['From'] = self.email_config['email']
            msg['To'] = self.email_config['email']
            msg['Subject'] = subject
            
            msg.attach(MIMEText(message, 'plain'))
            
            server = smtplib.SMTP(self.email_config['smtp_server'], self.email_config['smtp_port'])
            server.starttls()
            server.login(self.email_config['email'], self.email_config['password'])
            server.send_message(msg)
            server.quit()
            
        except Exception as e:
            logging.error(f"Email sending failed: {e}")
    
    def _trade_alert_template(self, signal: TradeSignal, symbol: str, price: float) -> str:
        """Format trade alert message"""
        emoji_map = {"buy": "üü¢", "sell": "üî¥", "hold": "‚ö´"}
        emoji = emoji_map.get(signal.action, "‚ö´")
        
        return f"""
{emoji} **HALAL TRADE SIGNAL** {emoji}

**Symbol**: {symbol}
**Action**: {signal.action.upper()}
**Price**: ${price:.4f}
**Confidence**: {signal.confidence:.1%} ({signal.signal_strength})
**Strategy**: {signal.strategy}
**Risk Level**: {signal.risk_level}

**Stop Loss**: ${signal.stop_loss:.4f}" if signal.stop_loss else "N/A"}
**Target**: ${signal.price_target:.4f}" if signal.price_target else "N/A"}

**Time**: {signal.timestamp.strftime('%Y-%m-%d %H:%M:%S UTC')}

*Automated signal from Enhanced Halal Trading Bot v2.2*
        """.strip()
    
    def _session_summary_template(self, report: str) -> str:
        """Format session summary message"""
        return f"""
üìä **TRADING SESSION COMPLETE**

{report}

*This is an automated summary from your Halal Trading Bot*
        """.strip()
    
    def _error_alert_template(self, error_msg: str, severity: str) -> str:
        """Format error alert message"""
        severity_emoji = {"low": "‚ÑπÔ∏è", "medium": "‚ö†Ô∏è", "high": "üö®", "critical": "üí•"}
        emoji = severity_emoji.get(severity, "‚ö†Ô∏è")
        
        return f"""
{emoji} **SYSTEM ALERT** - {severity.upper()}

**Error**: {error_msg}
**Time**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}
**Severity**: {severity.title()}

Please check the system logs for more details.

*Automated alert from Enhanced Halal Trading Bot v2.2*
        """.strip()

class EnhancedTechnicalAnalysis:
    """Enhanced technical analysis with caching and error handling"""
    
    def __init__(self):
        self.epsilon = 1e-8
        self.indicator_cache = {}
        self.cache_duration = timedelta(minutes=30)
        
        self.ta_config = {
            'sma_periods': [5, 10, 20, 50],
            'ema_periods': [12, 26],
            'rsi_period': 14,
            'macd_fast': 12,
            'macd_slow': 26,
            'macd_signal': 9,
            'bb_period': 20,
            'bb_std': 2,
            'atr_period': 14,
            'adx_period': 14
        }
    
    def calculate_indicators(self, df: pd.DataFrame, symbol: str = "") -> pd.DataFrame:
        """Calculate comprehensive technical indicators with caching"""
        if len(df) < 20:
            logging.warning(f"Insufficient data for indicators: {len(df)} bars")
            return pd.DataFrame(index=df.index)
        
        cache_key = self._get_cache_key(df, symbol)
        if cache_key in self.indicator_cache:
            cached_data, timestamp = self.indicator_cache[cache_key]
            if datetime.now() - timestamp < self.cache_duration:
                return cached_data
        
        try:
            if TALIB_AVAILABLE:
                indicators = self._calculate_talib_indicators(df)
            else:
                indicators = self._calculate_pandas_indicators(df)
            
            indicators = self._add_custom_indicators(df, indicators)
            indicators = self._add_pattern_indicators(df, indicators)
            indicators = self._clean_indicators(indicators)
            
            self.indicator_cache[cache_key] = (indicators, datetime.now())
            self._cleanup_cache()
            
            return indicators
            
        except Exception as e:
            logging.error(f"Error calculating indicators for {symbol}: {e}")
            return pd.DataFrame(index=df.index)

    def _get_cache_key(self, df: pd.DataFrame, symbol: str) -> str:
        """Generate cache key for indicator data"""
        last_timestamp = df.index[-1] if len(df) > 0 else datetime.now()
        return f"{symbol}_{len(df)}_{last_timestamp}_{df['close'].iloc[-1]:.4f}"

    def _calculate_talib_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """Calculate indicators using talib with comprehensive error handling"""
        close = df['close'].values.astype(float)
        high = df['high'].values.astype(float) if 'high' in df.columns else close
        low = df['low'].values.astype(float) if 'low' in df.columns else close
        volume = df['volume'].values.astype(float) if 'volume' in df.columns else np.ones(len(close))
        
        indicators = pd.DataFrame(index=df.index)
        
        try:
            for period in self.ta_config['sma_periods']:
                if len(close) >= period:
                    indicators[f'sma_{period}'] = talib.SMA(close, timeperiod=period)
            
            for period in self.ta_config['ema_periods']:
                if len(close) >= period:
                    indicators[f'ema_{period}'] = talib.EMA(close, timeperiod=period)
            
            if len(close) >= self.ta_config['rsi_period']:
                indicators['rsi'] = talib.RSI(close, timeperiod=self.ta_config['rsi_period'])
            
            if len(close) >= max(self.ta_config['macd_fast'], self.ta_config['macd_slow']):
                macd_line, macd_signal, macd_hist = talib.MACD(
                    close, 
                    fastperiod=self.ta_config['macd_fast'],
                    slowperiod=self.ta_config['macd_slow'],
                    signalperiod=self.ta_config['macd_signal']
                )
                indicators['macd'] = macd_line
                indicators['macd_signal'] = macd_signal
                indicators['macd_hist'] = macd_hist
            
            if len(close) >= 14:
                stoch_k, stoch_d = talib.STOCH(high, low, close)
                indicators['stoch_k'] = stoch_k
                indicators['stoch_d'] = stoch_d
            
            if len(close) >= 14:
                indicators['williams_r'] = talib.WILLR(high, low, close, timeperiod=14)
            
            if len(close) >= 10:
                indicators['roc'] = talib.ROC(close, timeperiod=10)
            
            if len(close) >= 14 and len(volume) >= 14:
                indicators['mfi'] = talib.MFI(high, low, close, volume, timeperiod=14)
            
            if len(close) >= self.ta_config['bb_period']:
                bb_upper, bb_middle, bb_lower = talib.BBANDS(
                    close, 
                    timeperiod=self.ta_config['bb_period'],
                    nbdevup=self.ta_config['bb_std'],
                    nbdevdn=self.ta_config['bb_std']
                )
                indicators['bb_upper'] = bb_upper
                indicators['bb_middle'] = bb_middle
                indicators['bb_lower'] = bb_lower
            
            if len(close) >= self.ta_config['atr_period']:
                indicators['atr'] = talib.ATR(high, low, close, timeperiod=self.ta_config['atr_period'])
            
            if len(volume) >= len(close):
                indicators['obv'] = talib.OBV(close, volume)
                indicators['ad'] = talib.AD(high, low, close, volume)
            
            if len(close) >= self.ta_config['adx_period']:
                indicators['adx'] = talib.ADX(high, low, close, timeperiod=self.ta_config['adx_period'])
                indicators['plus_di'] = talib.PLUS_DI(high, low, close, timeperiod=self.ta_config['adx_period'])
                indicators['minus_di'] = talib.MINUS_DI(high, low, close, timeperiod=self.ta_config['adx_period'])
            
            if len(close) >= 14:
                indicators['cci'] = talib.CCI(high, low, close, timeperiod=14)
            
            if len(close) >= 14:
                aroon_up, aroon_down = talib.AROON(high, low, timeperiod=14)
                indicators['aroon_up'] = aroon_up
                indicators['aroon_down'] = aroon_down
            
        except Exception as e:
            logging.error(f"Error in talib calculations: {e}")
        
        return indicators

    def _calculate_pandas_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """Calculate indicators using pandas_ta as fallback"""
        indicators = pd.DataFrame(index=df.index)
        
        try:
            import pandas_ta as ta
            
            df_ta = df.ta.strategy(ta.AllStrategy)
            
            column_mapping = {
                'SMA_10': 'sma_10',
                'SMA_20': 'sma_20',
                'SMA_50': 'sma_50',
                'EMA_12': 'ema_12',
                'EMA_26': 'ema_26',
                'RSI_14': 'rsi',
                'MACD_12_26_9': 'macd',
                'MACDs_12_26_9': 'macd_signal',
                'MACDh_12_26_9': 'macd_hist',
                'BBU_20_2.0': 'bb_upper',
                'BBM_20_2.0': 'bb_middle',
                'BBL_20_2.0': 'bb_lower',
                'ATRr_14': 'atr',
                'ADX_14': 'adx',
                'CCI_14_0.015': 'cci'
            }
            
            for old_name, new_name in column_mapping.items():
                if old_name in df_ta.columns:
                    indicators[new_name] = df_ta[old_name]
            
        except Exception as e:
            logging.error(f"Error in pandas_ta calculations: {e}")
            close = df['close']
            indicators['sma_20'] = close.rolling(20).mean()
            indicators['rsi'] = self._calculate_rsi_manual(close)
        
        return indicators

    def _calculate_rsi_manual(self, close_prices: pd.Series, period: int = 14) -> pd.Series:
        """Manual RSI calculation as fallback"""
        try:
            delta = close_prices.diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
            rs = gain / (loss + self.epsilon)
            rsi = 100 - (100 / (1 + rs))
            return rsi
        except Exception:
            return pd.Series(50, index=close_prices.index)  # Neutral RSI
    
    def _add_custom_indicators(self, df: pd.DataFrame, indicators: pd.DataFrame) -> pd.DataFrame:
        """Add custom technical indicators"""
        try:
            close = df['close']
            
            if all(col in indicators.columns for col in ['bb_upper', 'bb_lower']):
                bb_range = indicators['bb_upper'] - indicators['bb_lower']
                indicators['bb_position'] = (close - indicators['bb_lower']) / (bb_range + self.epsilon)
                indicators['bb_width'] = bb_range / close
            else:
                indicators['bb_position'] = 0.5
                indicators['bb_width'] = 0.02
            
            returns = close.pct_change()
            if len(returns) > 20:
                current_vol = returns.rolling(20).std()
                long_term_vol = returns.rolling(100).std() if len(returns) > 100 else current_vol
                indicators['volatility_regime'] = current_vol / (long_term_vol + self.epsilon)
                indicators['volatility_percentile'] = current_vol.rolling(252).rank(pct=True) if len(returns) > 252 else 0.5
            else:
                indicators['volatility_regime'] = 1.0
                indicators['volatility_percentile'] = 0.5
            
            for period in [3, 5, 10, 20]:
                if len(close) > period:
                    indicators[f'price_momentum_{period}'] = close / close.shift(period) - 1
            
            if 'volume' in df.columns:
                volume = df['volume']
                vol_sma = volume.rolling(20).mean()
                indicators['volume_ratio'] = volume / (vol_sma + self.epsilon)
                indicators['volume_momentum'] = volume / volume.shift(5) - 1
                
                indicators['pvt'] = ((close - close.shift(1)) / close.shift(1) * volume).cumsum()
            else:
                indicators['volume_ratio'] = 1.0
                indicators['volume_momentum'] = 0.0
                indicators['pvt'] = 0.0
            
            indicators['support_level'] = close.rolling(20).min()
            indicators['resistance_level'] = close.rolling(20).max()
            indicators['support_strength'] = (close - indicators['support_level']) / close
            indicators['resistance_strength'] = (indicators['resistance_level'] - close) / close
            
            if 'sma_20' in indicators.columns and 'sma_50' in indicators.columns:
                indicators['trend_strength'] = (indicators['sma_20'] - indicators['sma_50']) / close
            
            indicators['higher_highs'] = (close > close.shift(1)).rolling(5).sum() / 5
            indicators['lower_lows'] = (close < close.shift(1)).rolling(5).sum() / 5
            
        except Exception as e:
            logging.error(f"Error calculating custom indicators: {e}")
        
        return indicators

    def _add_pattern_indicators(self, df: pd.DataFrame, indicators: pd.DataFrame) -> pd.DataFrame:
        """Add pattern recognition indicators"""
        try:
            close = df['close']
            high = df['high'] if 'high' in df.columns else close
            low = df['low'] if 'low' in df.columns else close
            
            body_size = abs(close - df['open']) if 'open' in df.columns else 0
            candle_range = high - low
            indicators['doji_pattern'] = (body_size / (candle_range + self.epsilon)) < 0.1
            
            lower_shadow = close - low
            upper_shadow = high - close
            indicators['hammer_pattern'] = (lower_shadow > 2 * body_size) & (upper_shadow < 0.5 * body_size)
            
            if len(close) > 1:
                prev_close = close.shift(1)
                prev_open = df['open'].shift(1) if 'open' in df.columns else prev_close
                curr_open = df['open'] if 'open' in df.columns else close
                
                bullish_engulfing = (prev_close < prev_open) & (close > curr_open) & \
                                     (close > prev_open) & (curr_open < prev_close)
                bearish_engulfing = (prev_close > prev_open) & (close < curr_open) & \
                                     (close < prev_open) & (curr_open > prev_close)
                
                indicators['bullish_engulfing'] = bullish_engulfing
                indicators['bearish_engulfing'] = bearish_engulfing
            
            if len(close) > 1:
                gap_up = low > high.shift(1)
                gap_down = high < low.shift(1)
                indicators['gap_up'] = gap_up
                indicators['gap_down'] = gap_down
            
        except Exception as e:
            logging.error(f"Error calculating pattern indicators: {e}")
        
        return indicators
    
    def _clean_indicators(self, indicators: pd.DataFrame) -> pd.DataFrame:
        """Clean and validate indicator data"""
        try:
            indicators = indicators.fillna(method='ffill')
            
            neutral_values = {
                'rsi': 50,
                'bb_position': 0.5,
                'volatility_regime': 1.0,
                'volume_ratio': 1.0,
                'stoch_k': 50,
                'stoch_d': 50,
                'williams_r': -50,
                'cci': 0,
                'mfi': 50
            }
            
            for col, neutral_val in neutral_values.items():
                if col in indicators.columns:
                    indicators[col] = indicators[col].fillna(neutral_val)
            
            indicators = indicators.replace([np.inf, -np.inf], np.nan)
            indicators = indicators.fillna(0)
            
            return indicators
            
        except Exception as e:
            logging.error(f"Error cleaning indicators: {e}")
            return indicators
    
    def _cleanup_cache(self):
        """Clean up old cache entries"""
        try:
            current_time = datetime.now()
            expired_keys = [
                key for key, (_, timestamp) in self.indicator_cache.items()
                if current_time - timestamp > self.cache_duration * 2
            ]
            
            for key in expired_keys:
                del self.indicator_cache[key]
            
            if len(self.indicator_cache) > 100:
                sorted_items = sorted(
                    self.indicator_cache.items(),
                    key=lambda x: x[1][1]
                )
                for key, _ in sorted_items[:20]:
                    del self.indicator_cache[key]
                    
        except Exception as e:
            logging.error(f"Error cleaning cache: {e}")

class EnhancedMLStrategy:
    """Advanced ML strategy with ensemble methods and feature engineering"""
    
    def __init__(self, config: TradingConfig):
        self.config = config
        self.models = {}
        self.scalers = {}
        self.feature_selectors = {}
        self.feature_names = {}
        self.performance_history = {}
        self.model_path = Path("models")
        self.model_path.mkdir(exist_ok=True)
        
        self.ensemble_models = {
            'rf': RandomForestClassifier(
                n_estimators=200,
                max_depth=15,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42,
                class_weight='balanced',
                n_jobs=-1
            ),
            'gb': GradientBoostingClassifier(
                n_estimators=100,
                max_depth=8,
                learning_rate=0.1,
                random_state=42
            )
        } if self.config.ml_ensemble_models else {
            'rf': RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                class_weight='balanced'
            )
        }
    
    def prepare_enhanced_features(self, df: pd.DataFrame, indicators: pd.DataFrame) -> Tuple[Optional[pd.DataFrame], Optional[pd.Series], List[str]]:
        """Prepare enhanced feature set with better feature engineering"""
        try:
            if len(df) < self.config.ml_min_samples:
                logging.warning(f"Insufficient data for ML: {len(df)} < {self.config.ml_min_samples}")
                return None, None, []
            
            base_features = [
                'rsi', 'macd', 'macd_hist', 'bb_position', 'atr', 'adx', 'cci',
                'stoch_k', 'williams_r', 'volatility_regime', 'volume_ratio',
                'price_momentum_5', 'price_momentum_10'
            ]
            
            available_features = [col for col in base_features if col in indicators.columns]
            
            if len(available_features) < 5:
                logging.warning("Insufficient technical indicators for ML model")
                return None, None, []
            
            features = indicators[available_features].copy()
            
            close_prices = df['close']
            features['price_sma_ratio'] = close_prices / indicators.get('sma_20', close_prices)
            features['price_ema_ratio'] = close_prices / indicators.get('ema_12', close_prices)
            
            returns = close_prices.pct_change()
            features['realized_volatility'] = returns.rolling(20).std()
            features['volatility_zscore'] = (features['realized_volatility'] - 
                                             features['realized_volatility'].rolling(50).mean()) / \
                                            (features['realized_volatility'].rolling(50).std() + 1e-8)
            
            for period in [3, 5, 10, 20]:
                if len(close_prices) > period:
                    features[f'momentum_{period}'] = close_prices / close_prices.shift(period) - 1
                    features[f'volatility_{period}'] = returns.rolling(period).std()
            
            if 'volume' in df.columns:
                volume = df['volume']
                features['volume_sma_ratio'] = volume / volume.rolling(20).mean()
                features['volume_momentum'] = volume / volume.shift(5) - 1
                
                features['pv_trend'] = (returns * np.log1p(volume)).rolling(10).mean()
            
            lag_columns = ['rsi', 'macd', 'bb_position', 'price_momentum_5']
            for col in lag_columns:
                if col in features.columns:
                    for lag in [1, 2, 3]:
                        features[f'{col}_lag{lag}'] = features[col].shift(lag)
            
            features['bb_squeeze'] = ((indicators.get('bb_upper', close_prices) - 
                                            indicators.get('bb_lower', close_prices)) / 
                                            close_prices) < 0.02
            
            targets = self._create_enhanced_targets(close_prices, returns)
            
            valid_idx = features.dropna().index.intersection(targets.dropna().index)
            if len(valid_idx) < self.config.ml_min_samples:
                logging.warning(f"Insufficient valid samples after cleaning: {len(valid_idx)}")
                return None, None, []
            
            features = features.loc[valid_idx]
            targets = targets.loc[valid_idx]
            
            if self.config.ml_feature_selection and len(features.columns) > 20:
                features = self._select_features(features, targets)
            
            return features, targets, list(features.columns)
            
        except Exception as e:
            logging.error(f"Error preparing ML features: {e}")
            return None, None, []
    
    def _create_enhanced_targets(self, close_prices: pd.Series, returns: pd.Series) -> pd.Series:
        """Create enhanced target labels with adaptive thresholds"""
        volatility = returns.rolling(20).std()
        upper_threshold = volatility * 1.0
        lower_threshold = -volatility * 1.0
        
        future_returns_1 = returns.shift(-1)
        future_returns_3 = close_prices.pct_change(3).shift(-3)
        
        combined_signal = (future_returns_1 * 0.7 + future_returns_3 * 0.3)
        
        targets = pd.Series(1, index=combined_signal.index)
        
        targets[combined_signal < lower_threshold] = 0
        targets[combined_signal > upper_threshold] = 2
        
        return targets
    
    def _select_features(self, features: pd.DataFrame, targets: pd.Series) -> pd.DataFrame:
        """Select best features using statistical tests"""
        try:
            k = min(15, len(features.columns))
            selector = SelectKBest(score_func=f_classif, k=k)
            
            features_selected = selector.fit_transform(features.fillna(0), targets)
            selected_columns = features.columns[selector.get_support()].tolist()
            
            logging.info(f"Selected {len(selected_columns)} features from {len(features.columns)}")
            
            return pd.DataFrame(features_selected, 
                                 index=features.index, 
                                 columns=selected_columns)
        except Exception as e:
            logging.warning(f"Feature selection failed: {e}")
            return features
    
    def train_enhanced_model(self, features: pd.DataFrame, targets: pd.Series, symbol: str) -> bool:
        """Train enhanced ensemble model with cross-validation"""
        try:
            if len(features) < self.config.ml_min_samples:
                logging.warning(f"Insufficient samples for {symbol}: {len(features)}")
                return False
            
            scaler = RobustScaler()
            X_scaled = scaler.fit_transform(features.fillna(0))
            
            tscv = TimeSeriesSplit(n_splits=min(5, len(features) // 20))
            
            trained_models = {}
            model_scores = {}
            
            for model_name, base_model in self.ensemble_models.items():
                try:
                    cv_scores = cross_val_score(base_model, X_scaled, targets, cv=tscv, scoring='accuracy')
                    
                    if cv_scores.mean() > 0.4:
                        base_model.fit(X_scaled, targets)
                        trained_models[model_name] = base_model
                        model_scores[model_name] = cv_scores.mean()
                        
                        logging.info(f"‚úÖ {model_name} trained for {symbol}: "
                                     f"CV accuracy={cv_scores.mean():.3f}¬±{cv_scores.std():.3f}")
                    else:
                        logging.warning(f"‚ùå {model_name} performance too low for {symbol}: {cv_scores.mean():.3f}")
                        
                except Exception as e:
                    logging.error(f"Error training {model_name} for {symbol}: {e}")
                    continue
            
            if not trained_models:
                logging.warning(f"No viable models trained for {symbol}")
                return False
            
            self.models[symbol] = trained_models
            self.scalers[symbol] = scaler
            self.feature_names[symbol] = list(features.columns)
            
            if symbol not in self.performance_history:
                self.performance_history[symbol] = []
            
            best_score = max(model_scores.values())
            self.performance_history[symbol].append({
                'timestamp': datetime.now(),
                'best_accuracy': best_score,
                'models': list(model_scores.keys()),
                'model_scores': model_scores,
                'samples': len(features),
                'features': len(features.columns)
            })
            
            self._save_model(symbol, trained_models, scaler, features.columns, model_scores)
            
            logging.info(f"‚úÖ Ensemble model trained for {symbol}: "
                         f"best_accuracy={best_score:.3f}, models={len(trained_models)}")
            
            return True
            
        except Exception as e:
            logging.error(f"ML training failed for {symbol}: {e}")
            return False
    
    def _save_model(self, symbol: str, models: Dict, scaler, feature_names, scores: Dict):
        """Save model ensemble to disk"""
        try:
            model_data = {
                'models': models,
                'scaler': scaler,
                'features': list(feature_names),
                'scores': scores,
                'timestamp': datetime.now(),
                'config': {
                    'ensemble_models': self.config.ml_ensemble_models,
                    'feature_selection': self.config.ml_feature_selection,
                    'min_samples': self.config.ml_min_samples
                }
            }
            
            model_file = self.model_path / f"{symbol}_ml_model.joblib"
            joblib.dump(model_data, model_file, compress=3)
            
            backup_file = self.model_path / f"{symbol}_ml_model_backup.joblib"
            if model_file.exists():
                joblib.dump(model_data, backup_file, compress=3)
        
        except Exception as e:
            logging.error(f"Error saving model for {symbol}: {e}")
    
    def predict_enhanced(self, features: pd.DataFrame, symbol: str) -> Tuple[str, float]:
        """Enhanced prediction with ensemble voting and confidence estimation"""
        try:
            if symbol not in self.models or len(features) == 0:
                return 'hold', 0.0
            
            if symbol not in self.models:
                success = self._load_model(symbol)
                if not success:
                    return 'hold', 0.0
            
            try:
                latest_features = features.iloc[-1:][self.feature_names[symbol]]
                latest_scaled = self.scalers[symbol].transform(latest_features.fillna(0))
            except KeyError as e:
                logging.warning(f"Feature mismatch for {symbol}: {e}")
                return 'hold', 0.0
            
            predictions = []
            confidences = []
            model_weights = []
            
            for model_name, model in self.models[symbol].items():
                try:
                    pred_proba = model.predict_proba(latest_scaled)[0]
                    prediction = model.predict(latest_scaled)[0]
                    confidence = max(pred_proba)
                    
                    weight = self._get_model_weight(symbol, model_name)
                    
                    predictions.append(prediction)
                    confidences.append(confidence)
                    model_weights.append(weight)
                    
                except Exception as e:
                    logging.warning(f"Prediction failed for {model_name} on {symbol}: {e}")
                    continue
            
            if not predictions:
                return 'hold', 0.0
            
            predictions = np.array(predictions)
            confidences = np.array(confidences)
            model_weights = np.array(model_weights)
            
            model_weights = model_weights / model_weights.sum()
            
            weighted_prediction = np.average(predictions, weights=model_weights)
            weighted_confidence = np.average(confidences, weights=model_weights)
            
            if weighted_prediction >= 1.7 and weighted_confidence > 0.6:
                return 'buy', weighted_confidence
            elif weighted_prediction <= 0.3 and weighted_confidence > 0.6:
                return 'sell', weighted_confidence
            else:
                return 'hold', weighted_confidence
                
        except Exception as e:
            logging.error(f"ML prediction failed for {symbol}: {e}")
            return 'hold', 0.0
    
    def _get_model_weight(self, symbol: str, model_name: str) -> float:
        """Get model weight based on historical performance"""
        try:
            if symbol not in self.performance_history:
                return 1.0
            
            recent_history = self.performance_history[symbol][-5:]
            if not recent_history:
                return 1.0
            
            scores = []
            for hist in recent_history:
                if model_name in hist.get('model_scores', {}):
                    scores.append(hist['model_scores'][model_name])
            
            if scores:
                return max(0.1, np.mean(scores))
            return 1.0
            
        except Exception:
            return 1.0
    
    def _load_model(self, symbol: str) -> bool:
        """Load model from disk"""
        try:
            model_file = self.model_path / f"{symbol}_ml_model.joblib"
            if not model_file.exists():
                return False
            
            model_data = joblib.load(model_file)
            self.models[symbol] = model_data['models']
            self.scalers[symbol] = model_data['scaler']
            self.feature_names[symbol] = model_data['features']
            
            logging.info(f"‚úÖ Model loaded for {symbol}")
            return True
            
        except Exception as e:
            logging.error(f"Error loading model for {symbol}: {e}")
            return False
            
    def should_retrain(self, symbol: str, samples: int) -> bool:
        """Determine if a model needs to be retrained"""
        if symbol not in self.models:
            return True
        
        last_train = self.performance_history.get(symbol, [{}])[-1].get('timestamp')
        if last_train is None or (datetime.now() - last_train) > timedelta(hours=self.config.ml_retrain_hours):
            logging.info(f"ML model for {symbol} is outdated, initiating retraining...")
            return True
        
        last_samples = self.performance_history.get(symbol, [{}])[-1].get('samples', 0)
        if samples > last_samples * 1.1:
            logging.info(f"New data available for {symbol}, initiating retraining...")
            return True
        
        return False

class AdvancedTradingStrategies:
    """Enhanced trading strategies with adaptive parameters and improved logic"""
    
    def __init__(self, config: TradingConfig):
        self.config = config
        self.ta = EnhancedTechnicalAnalysis()
        self.ml = EnhancedMLStrategy(config) if ML_AVAILABLE else None
        self.strategy_performance = {}
        self.adaptive_thresholds = {}
        self.strategy_cache = {}
        
        self.momentum_config = {
            'rsi_oversold': 30,
            'rsi_overbought': 70,
            'bb_lower_threshold': 0.2,
            'bb_upper_threshold': 0.8,
            'volume_confirmation': 1.5,
            'momentum_threshold': 0.02
        }
        
        self.mean_reversion_config = {
            'rsi_extreme_oversold': 25,
            'rsi_extreme_overbought': 75,
            'bb_extreme_lower': 0.1,
            'bb_extreme_upper': 0.9,
            'zscore_threshold': 1.5,
            'reversion_target_ratio': 0.98
        }
    
    def get_adaptive_threshold(self, symbol: str, base_threshold: float = 0.4) -> float:
        """Calculate adaptive threshold based on recent performance and market conditions"""
        try:
            if symbol not in self.strategy_performance:
                return base_threshold
            
            recent_signals = self.strategy_performance[symbol][-20:]
            if len(recent_signals) < 5:
                return base_threshold
            
            correct_predictions = sum(1 for signal in recent_signals if signal.get('correct', False))
            success_rate = correct_predictions / len(recent_signals)
            
            recent_volatility = np.mean([signal.get('market_volatility', 1.0) for signal in recent_signals])
            volatility_adjustment = min(0.2, max(-0.2, (recent_volatility - 1.0) * 0.3))
            
            if success_rate > 0.7:
                performance_adjustment = -0.1
            elif success_rate < 0.4:
                performance_adjustment = 0.2
            else:
                performance_adjustment = 0
            
            adjusted_threshold = base_threshold + performance_adjustment + volatility_adjustment
            adjusted_threshold = max(0.2, min(0.8, adjusted_threshold))
            
            self.adaptive_thresholds[symbol] = adjusted_threshold
            
            logging.debug(f"Adaptive threshold for {symbol}: {adjusted_threshold:.3f} "
                          f"(success_rate={success_rate:.2f}, volatility={recent_volatility:.2f})")
            
            return adjusted_threshold
            
        except Exception as e:
            logging.error(f"Error calculating adaptive threshold for {symbol}: {e}")
            return base_threshold
    
    def momentum_breakout_strategy(self, df: pd.DataFrame, indicators: pd.DataFrame, 
                                  asset_config: AssetConfig) -> TradeSignal:
        """Enhanced momentum breakout strategy with multiple confirmation signals"""
        try:
            if len(df) < 20:
                return TradeSignal('hold', 0.0, 'momentum_breakout_insufficient_data')
            
            latest_idx = -1
            current_price = df['close'].iloc[latest_idx]
            
            rsi = self._safe_get_indicator(indicators, 'rsi', latest_idx, 50)
            bb_position = self._safe_get_indicator(indicators, 'bb_position', latest_idx, 0.5)
            vol_regime = self._safe_get_indicator(indicators, 'volatility_regime', latest_idx, 1.0)
            volume_ratio = self._safe_get_indicator(indicators, 'volume_ratio', latest_idx, 1.0)
            atr = self._safe_get_indicator(indicators, 'atr', latest_idx, current_price * 0.02)
            adx = self._safe_get_indicator(indicators, 'adx', latest_idx, 25)
            
            sma_20 = self._safe_get_indicator(indicators, 'sma_20', latest_idx, current_price)
            sma_50 = self._safe_get_indicator(indicators, 'sma_50', latest_idx, current_price)
            price_momentum = (current_price / sma_20 - 1) if sma_20 > 0 else 0
            trend_alignment = sma_20 > sma_50 if sma_50 > 0 else True
            
            volume_confirmation = volume_ratio > self.momentum_config['volume_confirmation']
            momentum_strength = abs(price_momentum)
            trend_strength = adx > 25
            volatility_normal = vol_regime < 2.0
            
            confidence = 0.0
            action = 'hold'
            
            bullish_conditions = [
                rsi > self.momentum_config['rsi_oversold'] and rsi < self.momentum_config['rsi_overbought'],
                bb_position > self.momentum_config['bb_upper_threshold'],
                price_momentum > self.momentum_config['momentum_threshold'],
                volume_confirmation,
                trend_alignment,
                trend_strength,
                volatility_normal
            ]
            
            bullish_score = sum(bullish_conditions)
            
            if bullish_score >= 5:
                base_confidence = 0.4 + (bullish_score - 5) * 0.1
                momentum_boost = min(0.25, momentum_strength * 10)
                volume_boost = min(0.1, (volume_ratio - 1.5) * 0.1) if volume_confirmation else 0
                trend_boost = min(0.1, (adx - 25) / 100)
                
                confidence = min(0.95, base_confidence + momentum_boost + volume_boost + trend_boost)
                action = 'buy'
            
            bearish_conditions = [
                rsi < self.momentum_config['rsi_overbought'] and rsi > self.momentum_config['rsi_oversold'],
                bb_position < self.momentum_config['bb_lower_threshold'],
                price_momentum < -self.momentum_config['momentum_threshold'],
                volume_confirmation,
                not trend_alignment,
                trend_strength,
                volatility_normal
            ]
            
            bearish_score = sum(bearish_conditions)
            
            if bearish_score >= 5 and confidence == 0:
                base_confidence = 0.4 + (bearish_score - 5) * 0.1
                momentum_boost = min(0.25, momentum_strength * 10)
                volume_boost = min(0.1, (volume_ratio - 1.5) * 0.1) if volume_confirmation else 0
                trend_boost = min(0.1, (adx - 25) / 100)
                
                confidence = min(0.95, base_confidence + momentum_boost + volume_boost + trend_boost)
                action = 'sell'
            
            if action == 'buy':
                stop_loss = current_price - (atr * (2.0 + vol_regime * 0.5))
                price_target = current_price + (atr * (3.0 + vol_regime * 0.5))
            elif action == 'sell':
                stop_loss = current_price + (atr * (2.0 + vol_regime * 0.5))
                price_target = current_price - (atr * (3.0 + vol_regime * 0.5))
            else:
                stop_loss = None
                price_target = None
            
            signal = TradeSignal(action, confidence, 'momentum_breakout', price_target, stop_loss)
            
            logging.debug(f"Momentum signal for {asset_config.symbol}: {action} "
                          f"(conf={confidence:.2f}, bullish={bullish_score}, bearish={bearish_score})")
            
            return signal
            
        except Exception as e:
            logging.error(f"Momentum strategy error for {asset_config.symbol}: {e}")
            return TradeSignal('hold', 0.0, 'momentum_breakout_error')
    
    def mean_reversion_strategy(self, df: pd.DataFrame, indicators: pd.DataFrame,
                              asset_config: AssetConfig) -> TradeSignal:
        """Enhanced mean reversion strategy with improved statistical measures"""
        try:
            if len(df) < 20:
                return TradeSignal('hold', 0.0, 'mean_reversion_insufficient_data')
            
            latest_idx = -1
            current_price = df['close'].iloc[latest_idx]
            
            rsi = self._safe_get_indicator(indicators, 'rsi', latest_idx, 50)
            bb_position = self._safe_get_indicator(indicators, 'bb_position', latest_idx, 0.5)
            williams_r = self._safe_get_indicator(indicators, 'williams_r', latest_idx, -50)
            cci = self._safe_get_indicator(indicators, 'cci', latest_idx, 0)
            
            sma_20 = self._safe_get_indicator(indicators, 'sma_20', latest_idx, current_price)
            sma_50 = self._safe_get_indicator(indicators, 'sma_50', latest_idx, current_price)
            support_level = self._safe_get_indicator(indicators, 'support_level', latest_idx, current_price * 0.95)
            resistance_level = self._safe_get_indicator(indicators, 'resistance_level', latest_idx, current_price * 1.05)
            
            returns = df['close'].pct_change()
            price_std = returns.rolling(20).std().iloc[latest_idx] if len(returns) > 20 else 0.02
            z_score_20 = (current_price - sma_20) / (price_std * sma_20 + 1e-8) if price_std > 0 else 0
            
            distance_from_support = (current_price - support_level) / current_price if support_level > 0 else 0.1
            distance_from_resistance = (resistance_level - current_price) / current_price if resistance_level > 0 else 0.1
            
            vol_regime = self._safe_get_indicator(indicators, 'volatility_regime', latest_idx, 1.0)
            is_ranging_market = vol_regime < 1.5 and abs(sma_20 - sma_50) / current_price < 0.02
            
            confidence = 0.0
            action = 'hold'
            
            oversold_conditions = [
                rsi < self.mean_reversion_config['rsi_extreme_oversold'],
                bb_position < self.mean_reversion_config['bb_extreme_lower'],
                williams_r < -85,
                cci < -150,
                z_score_20 < -self.mean_reversion_config['zscore_threshold'],
                distance_from_support < 0.02,
                is_ranging_market,
                current_price < sma_20 * self.mean_reversion_config['reversion_target_ratio']
            ]
            
            oversold_score = sum(oversold_conditions)
            
            if oversold_score >= 4:
                base_confidence = 0.3 + oversold_score * 0.08
                
                rsi_boost = max(0, (30 - rsi) / 100) if rsi < 30 else 0
                bb_boost = max(0, (0.15 - bb_position) * 2) if bb_position < 0.15 else 0
                zscore_boost = max(0, abs(z_score_20) - 1.5) * 0.1
                support_boost = max(0, (0.02 - distance_from_support) * 5) if distance_from_support < 0.02 else 0
                
                confidence = min(0.9, base_confidence + rsi_boost + bb_boost + zscore_boost + support_boost)
                action = 'buy'
            
            overbought_conditions = [
                rsi > self.mean_reversion_config['rsi_extreme_overbought'],
                bb_position > self.mean_reversion_config['bb_extreme_upper'],
                williams_r > -15,
                cci > 150,
                z_score_20 > self.mean_reversion_config['zscore_threshold'],
                distance_from_resistance < 0.02,
                is_ranging_market,
                current_price > sma_20 * (2 - self.mean_reversion_config['reversion_target_ratio'])
            ]
            
            overbought_score = sum(overbought_conditions)
            
            if overbought_score >= 4 and confidence == 0:
                base_confidence = 0.3 + overbought_score * 0.08
                
                rsi_boost = max(0, (rsi - 70) / 100) if rsi > 70 else 0
                bb_boost = max(0, (bb_position - 0.85) * 2) if bb_position > 0.85 else 0
                zscore_boost = max(0, abs(z_score_20) - 1.5) * 0.1
                resistance_boost = max(0, (0.02 - distance_from_resistance) * 5) if distance_from_resistance < 0.02 else 0
                
                confidence = min(0.9, base_confidence + rsi_boost + bb_boost + zscore_boost + resistance_boost)
                action = 'sell'
            
            atr = self._safe_get_indicator(indicators, 'atr', latest_idx, current_price * 0.02)
            
            if action == 'buy':
                price_target = sma_20
                stop_loss = min(current_price * 0.96, support_level * 0.99)
            elif action == 'sell':
                price_target = sma_20
                stop_loss = max(current_price * 1.04, resistance_level * 1.01)
            else:
                price_target = None
                stop_loss = None
            
            signal = TradeSignal(action, confidence, 'mean_reversion', price_target, stop_loss)
            
            logging.debug(f"Mean reversion signal for {asset_config.symbol}: {action} "
                          f"(conf={confidence:.2f}, oversold={oversold_score}, overbought={overbought_score})")
            
            return signal
            
        except Exception as e:
            logging.error(f"Mean reversion strategy error for {asset_config.symbol}: {e}")
            return TradeSignal('hold', 0.0, 'mean_reversion_error')
    
    def _safe_get_indicator(self, indicators: pd.DataFrame, column: str, 
                            index: int, default_value: float) -> float:
        """Safely get indicator value with fallback"""
        try:
            if column in indicators.columns and len(indicators) > abs(index):
                value = indicators[column].iloc[index]
                if pd.isna(value) or np.isinf(value):
                    return default_value
                return float(value)
            return default_value
        except (IndexError, KeyError, ValueError):
            return default_value
    
    def update_strategy_performance(self, symbol: str, signal: TradeSignal, 
                                  actual_return: float, market_volatility: float):
        """Update strategy performance tracking"""
        try:
            if symbol not in self.strategy_performance:
                self.strategy_performance[symbol] = []
            
            correct = False
            if signal.action == 'buy' and actual_return > 0.01:
                correct = True
            elif signal.action == 'sell' and actual_return < -0.01:
                correct = True
            elif signal.action == 'hold' and abs(actual_return) < 0.01:
                correct = True
            
            performance_entry = {
                'timestamp': signal.timestamp,
                'action': signal.action,
                'confidence': signal.confidence,
                'strategy': signal.strategy,
                'actual_return': actual_return,
                'market_volatility': market_volatility,
                'correct': correct
            }
            
            self.strategy_performance[symbol].append(performance_entry)
            
            if len(self.strategy_performance[symbol]) > 100:
                self.strategy_performance[symbol] = self.strategy_performance[symbol][-100:]
                
        except Exception as e:
            logging.error(f"Error updating strategy performance for {symbol}: {e}")

class AdvancedHalalScreener:
    """Enhanced halal compliance screening with real-time data integration"""
    
    def __init__(self, config: TradingConfig):
        self.config = config
        self.screening_cache = {}
        self.screening_history = {}
        self.cache_duration = timedelta(hours=24)
        
        self.prohibited_activities = {
            'alcohol': {
                'keywords': ['ALCOHOL', 'BEER', 'WINE', 'SPIRITS', 'BREWERY', 'DISTILLERY', 'LIQUOR'],
                'severity': 1.0
            },
            'gambling': {
                'keywords': ['GAMBLING', 'CASINO', 'LOTTERY', 'GAMING', 'BETTING', 'POKER'],
                'severity': 1.0
            },
            'tobacco': {
                'keywords': ['TOBACCO', 'CIGARETTE', 'CIGAR', 'SMOKING', 'NICOTINE'],
                'severity': 1.0
            },
            'adult_entertainment': {
                'keywords': ['ADULT', 'ENTERTAINMENT', 'PORNOGRAPHY', 'ESCORT'],
                'severity': 1.0
            },
            'weapons': {
                'keywords': ['WEAPONS', 'DEFENSE', 'MILITARY', 'ARMS', 'AMMUNITION', 'FIREARMS'],
                'severity': 0.9
            },
            'pork': {
                'keywords': ['PORK', 'PIG', 'SWINE', 'HAM', 'BACON'],
                'severity': 1.0
            },
            'conventional_finance': {
                'keywords': ['CONVENTIONAL_BANKING', 'INTEREST_BASED', 'DERIVATIVES', 'SPECULATION'],
                'severity': 0.8
            },
            'insurance': {
                'keywords': ['INSURANCE', 'REINSURANCE', 'LIFE_INSURANCE'],
                'severity': 0.7
            }
        }
        
        self.preferred_industries = {
            'technology': ['SOFTWARE', 'TECHNOLOGY', 'COMPUTER', 'INTERNET', 'TELECOMMUNICATIONS'],
            'healthcare': ['HEALTHCARE', 'MEDICAL', 'PHARMACEUTICAL', 'BIOTECH'],
            'renewable_energy': ['SOLAR', 'WIND', 'RENEWABLE', 'CLEAN_ENERGY'],
            'halal_food': ['HALAL', 'ORGANIC', 'FOOD', 'AGRICULTURE'],
            'education': ['EDUCATION', 'TRAINING', 'LEARNING'],
            'real_estate': ['REAL_ESTATE', 'PROPERTY', 'REIT']
        }
    
    async def comprehensive_screening(self, symbol: str) -> Dict[str, any]:
        """Enhanced comprehensive halal screening with caching and real-time data"""
        
        if symbol in self.screening_cache:
            cached_result = self.screening_cache[symbol]
            if datetime.now() - cached_result['timestamp'] < self.cache_duration:
                logging.debug(f"Using cached screening result for {symbol}")
                return cached_result
        
        results = {
            'symbol': symbol,
            'is_halal': False,
            'business_screening': await self._enhanced_business_screening(symbol),
            'financial_screening': await self._enhanced_financial_screening(symbol),
            'compliance_score': 0.0,
            'warnings': [],
            'recommendations': [],
            'positive_factors': [],
            'last_updated': datetime.now(),
            'timestamp': datetime.now(),
            'data_sources': []
        }
        
        business_results = results['business_screening']
        if not business_results['passed']:
            results['warnings'].extend(business_results['violations'])
            results['compliance_score'] = 0.0
            results['is_halal'] = False
            self._cache_result(symbol, results)
            return results
        
        results['positive_factors'].extend(business_results.get('positive_factors', []))
        
        financial_results = results['financial_screening']
        compliance_score = 1.0
        
        # Check if financial data is available and not a fallback
        if financial_results.get('data_source') == 'error_fallback':
            logging.warning(f"‚ùå Financial data for {symbol} is a fallback, cannot determine compliance accurately.")
            results['warnings'].append("Financial data is unavailable or unreliable. Cannot verify compliance.")
            results['compliance_score'] = 0.0
            results['is_halal'] = False
            self._cache_result(symbol, results)
            return results

        debt_ratio = financial_results['debt_ratio']
        if debt_ratio > 0.33:
            if debt_ratio > 0.50:
                penalty = 0.6
            elif debt_ratio > 0.40:
                penalty = 0.4
            else:
                penalty = min(0.3, (debt_ratio - 0.33) * 1.5)
            
            compliance_score -= penalty
            results['warnings'].append(f"High debt ratio: {debt_ratio:.1%} (limit: 33%)")
        
        interest_ratio = financial_results['interest_income_ratio']
        if interest_ratio > 0.05:
            penalty = min(0.4, (interest_ratio - 0.05) * 8)
            compliance_score -= penalty
            results['warnings'].append(f"High interest income: {interest_ratio:.1%} (limit: 5%)")
        
        liquid_ratio = financial_results['liquid_assets_ratio']
        if liquid_ratio > 0.70:
            penalty = min(0.3, (liquid_ratio - 0.70) * 1.0)
            compliance_score -= penalty
            results['warnings'].append(f"High liquid assets ratio: {liquid_ratio:.1%} (limit: 70%)")
        
        prohibited_revenue = financial_results.get('revenue_from_prohibited', 0.0)
        if prohibited_revenue > 0.05:
            penalty = min(0.5, prohibited_revenue * 10)
            compliance_score -= penalty
            results['warnings'].append(f"Revenue from prohibited activities: {prohibited_revenue:.1%}")
        
        if debt_ratio < 0.20:
            results['positive_factors'].append(f"Low debt ratio: {debt_ratio:.1%}")
        if interest_ratio < 0.02:
            results['positive_factors'].append(f"Minimal interest income: {interest_ratio:.1%}")
        if financial_results.get('dividend_yield', 0) > 0.02:
            results['positive_factors'].append("Regular dividend payments")
        
        esg_score = financial_results.get('esg_score', 0.5)
        if esg_score > 0.7:
            compliance_score += 0.05
            results['positive_factors'].append(f"Strong ESG score: {esg_score:.1%}")
        
        results['compliance_score'] = max(0, compliance_score)
        
        base_threshold = 0.70
        warning_penalty = len(results['warnings']) * 0.05
        positive_bonus = min(0.10, len(results['positive_factors']) * 0.02)
        
        effective_threshold = base_threshold + warning_penalty - positive_bonus
        results['is_halal'] = (compliance_score >= effective_threshold and 
                                 len([w for w in results['warnings'] if 'High' in w]) <= 2)
        
        if not results['is_halal']:
            results['recommendations'] = self._generate_enhanced_recommendations(results)
        else:
            results['recommendations'] = ["Asset approved for halal investment"]
        
        self._cache_result(symbol, results)
        self.screening_history[symbol] = results
        
        status_emoji = "‚úÖ APPROVED" if results['is_halal'] else "‚ùå REJECTED"
        logging.info(f"Halal screening for {symbol}: {status_emoji} "
                     f"(Score: {results['compliance_score']:.1%}, Warnings: {len(results['warnings'])})")
        
        return results
    
    async def _enhanced_business_screening(self, symbol: str) -> Dict[str, any]:
        """Enhanced business activity screening with industry analysis"""
        try:
            violations = []
            positive_factors = []
            industry_info = await self._get_company_industry(symbol)
            
            company_data = await self._get_company_data(symbol)
            business_description = company_data.get('description', '').upper()
            industry = company_data.get('industry', '').upper()
            sector = company_data.get('sector', '').upper()
            
            total_severity = 0.0
            for category, info in self.prohibited_activities.items():
                keywords = info['keywords']
                severity = info['severity']
                
                found_keywords = []
                for keyword in keywords:
                    if (keyword in business_description or 
                        keyword in industry or 
                        keyword in sector):
                        found_keywords.append(keyword)
                
                if found_keywords:
                    violation_severity = severity * len(found_keywords) / len(keywords)
                    total_severity += violation_severity
                    violations.append(f"Prohibited activity ({category}): {', '.join(found_keywords)}")
            
            for category, keywords in self.preferred_industries.items():
                found_preferred = [kw for kw in keywords if kw in business_description or kw in industry]
                if found_preferred:
                    positive_factors.append(f"Preferred industry ({category}): {', '.join(found_preferred)}")
            
            esg_data = company_data.get('esg', {})
            if esg_data.get('environmental_score', 0) > 0.7:
                positive_factors.append("Strong environmental practices")
            if esg_data.get('social_score', 0) > 0.7:
                positive_factors.append("Strong social responsibility")
            
            return {
                'passed': total_severity < 0.1,
                'violations': violations,
                'positive_factors': positive_factors,
                'categories_checked': list(self.prohibited_activities.keys()),
                'industry_info': industry_info,
                'total_severity': total_severity
            }
            
        except Exception as e:
            logging.error(f"Business screening error for {symbol}: {e}")
            return {
                'passed': False, 
                'violations': ['Business screening error'], 
                'positive_factors': [],
                'categories_checked': [],
                'total_severity': 1.0
            }
    
    async def _enhanced_financial_screening(self, symbol: str) -> Dict[str, any]:
        """Enhanced financial screening with real-time data"""
        try:
            financial_data = await self._fetch_financial_data(symbol)
            
            return {
                'debt_ratio': financial_data.get('debt_ratio', 0.30),
                'interest_income_ratio': financial_data.get('interest_income_ratio', 0.03),
                'liquid_assets_ratio': financial_data.get('liquid_assets_ratio', 0.40),
                'revenue_from_prohibited': financial_data.get('prohibited_revenue_ratio', 0.0),
                'dividend_yield': financial_data.get('dividend_yield', 0.0),
                'esg_score': financial_data.get('esg_score', 0.5),
                'profitability_score': financial_data.get('profitability_score', 0.5),
                'data_source': financial_data.get('source', 'simulated'),
                'last_updated': datetime.now(),
                'data_quality': financial_data.get('quality_score', 0.7)
            }
            
        except Exception as e:
            logging.error(f"Financial screening error for {symbol}: {e}")
            return {
                'debt_ratio': 0.45,
                'interest_income_ratio': 0.08,
                'liquid_assets_ratio': 0.75,
                'revenue_from_prohibited': 0.05,
                'dividend_yield': 0.0,
                'esg_score': 0.3,
                'profitability_score': 0.3,
                'data_source': 'error_fallback',
                'last_updated': datetime.now(),
                'data_quality': 0.1
            }
    
    async def _get_company_data(self, symbol: str) -> Dict[str, any]:
        """Fetch comprehensive company data from multiple sources"""
        try:
            company_data = {
                'description': f'Technology company for {symbol}',
                'industry': 'Software',
                'sector': 'Technology',
                'esg': {
                    'environmental_score': np.random.uniform(0.3, 0.9),
                    'social_score': np.random.uniform(0.3, 0.9),
                    'governance_score': np.random.uniform(0.3, 0.9)
                }
            }
            return company_data
            
        except Exception as e:
            logging.error(f"Error fetching company data for {symbol}: {e}")
            return {}
    
    async def _get_company_industry(self, symbol: str) -> Dict[str, any]:
        """Get detailed industry classification"""
        try:
            return {
                'primary_industry': 'Technology',
                'sub_industry': 'Software',
                'industry_group': 'Information Technology',
                'business_summary': f'Company {symbol} operates in technology sector'
            }
        except Exception as e:
            logging.error(f"Error fetching industry data for {symbol}: {e}")
            return {}
    
    async def _fetch_financial_data(self, symbol: str) -> Dict[str, any]:
        """Fetch real-time financial data"""
        try:
            np.random.seed(hash(symbol) % 2147483647)
            
            financial_data = {
                'debt_ratio': max(0, np.random.normal(0.25, 0.15)),
                'interest_income_ratio': max(0, np.random.normal(0.02, 0.03)),
                'liquid_assets_ratio': np.random.uniform(0.1, 0.8),
                'prohibited_revenue_ratio': max(0, np.random.normal(0.0, 0.02)),
                'dividend_yield': max(0, np.random.normal(0.02, 0.02)),
                'esg_score': np.random.uniform(0.3, 0.9),
                'profitability_score': np.random.uniform(0.2, 0.9),
                'source': 'mock_api',
                'quality_score': 0.8
            }
            return financial_data
            
        except Exception as e:
            logging.error(f"Error fetching financial data for {symbol}: {e}")
            return {'source': 'error', 'quality_score': 0.0}
    
    def _generate_enhanced_recommendations(self, results: Dict) -> List[str]:
        """Generate detailed recommendations based on screening results"""
        recommendations = []
        
        financial = results['financial_screening']
        
        if financial['debt_ratio'] > 0.40:
            recommendations.append(
                f"High debt concern: Monitor debt reduction - current {financial['debt_ratio']:.1%} vs 33% limit"
            )
        elif financial['debt_ratio'] > 0.33:
            recommendations.append(
                f"Borderline debt ratio: Watch closely - current {financial['debt_ratio']:.1%}"
            )
        
        if financial['interest_income_ratio'] > 0.08:
            recommendations.append("Significant interest income - consider Islamic banking alternatives")
        elif financial['interest_income_ratio'] > 0.05:
            recommendations.append("Monitor interest income levels")
        
        if financial['liquid_assets_ratio'] > 0.80:
            recommendations.append("Very high liquid assets - may indicate lack of productive investment")
        
        business = results['business_screening']
        if business['violations']:
            recommendations.append("Core business activities conflict with Islamic principles - avoid investment")
        
        if financial.get('esg_score', 0) < 0.5:
            recommendations.append("Consider ESG factors - low environmental/social responsibility score")
        
        if financial.get('data_quality', 1.0) < 0.6:
            recommendations.append("Limited financial data available - conduct additional due diligence")
        
        if results['compliance_score'] > 0.85:
            recommendations.append("Excellent halal compliance - suitable for Islamic investment")
        elif results['compliance_score'] > 0.75:
            recommendations.append("Good halal compliance with minor concerns")
        
        return recommendations
    
    def _cache_result(self, symbol: str, results: Dict):
        """Cache screening results with memory management"""
        try:
            self.screening_cache[symbol] = results
            
            if len(self.screening_cache) > 500:
                sorted_items = sorted(
                    self.screening_cache.items(),
                    key=lambda x: x[1]['timestamp']
                )
                for key, _ in sorted_items[:100]:
                    del self.screening_cache[key]
                    
        except Exception as e:
            logging.error(f"Error caching screening result for {symbol}: {e}")
    
    def is_halal_crypto(self, symbol: str) -> bool:
        """Enhanced crypto halal screening with detailed analysis"""
        try:
            approved_crypto = {
                'BTC/USDT': {
                    'reason': 'Digital store of value with limited supply and no interest-bearing mechanism',
                    'risk_level': 'medium',
                    'utility_score': 0.9
                },
                'ETH/USDT': {
                    'reason': 'Smart contract platform enabling decentralized applications',
                    'risk_level': 'medium',
                    'utility_score': 0.85
                },
                'ADA/USDT': {
                    'reason': 'Research-driven blockchain with academic backing and proof-of-stake',
                    'risk_level': 'low',
                    'utility_score': 0.8
                },
                'DOT/USDT': {
                    'reason': 'Blockchain interoperability protocol with clear utility',
                    'risk_level': 'medium',
                    'utility_score': 0.75
                },
                'SOL/USDT': {
                    'reason': 'High-performance blockchain for decentralized applications',
                    'risk_level': 'medium',
                    'utility_score': 0.8
                },
                'AVAX/USDT': {
                    'reason': 'Decentralized platform for applications and custom blockchains',
                    'risk_level': 'medium',
                    'utility_score': 0.75
                },
                'ALGO/USDT': {
                    'reason': 'Pure proof-of-stake blockchain with academic foundation',
                    'risk_level': 'low',
                    'utility_score': 0.8
                },
                'XTZ/USDT': {
                    'reason': 'Self-amending blockchain protocol with governance features',
                    'risk_level': 'low',
                    'utility_score': 0.7
                }
            }
            
            prohibited_features = {
                'PRIVACY': 'Privacy coins may facilitate illicit activities',
                'GAMBLING': 'Gambling-related tokens prohibited',
                'INTEREST': 'Interest-bearing mechanisms prohibited',
                'LEVERAGE': 'Leveraged tokens involve excessive speculation',
                'SYNTHETIC': 'Synthetic assets may involve prohibited derivatives',
                'MARGIN': 'Margin trading involves interest-based borrowing',
                'LENDING': 'Lending protocols typically involve interest',
                'DEFI': 'Some DeFi protocols involve prohibited financial mechanisms'
            }
            
            prohibited_symbols = {
                'XMR': 'Privacy coin - Monero',
                'ZEC': 'Privacy coin - Zcash',
                'DASH': 'Privacy-focused cryptocurrency',
                'COMP': 'DeFi lending protocol token',
                'AAVE': 'DeFi lending protocol token',
                'MKR': 'DeFi protocol with interest mechanisms',
                'UNI': 'DEX token with potential interest mechanisms',
                'SUSHI': 'DeFi platform token',
                'CRV': 'DeFi protocol token',
                'YFI': 'DeFi yield farming token'
            }
            
            for prohibited_symbol, reason in prohibited_symbols.items():
                if prohibited_symbol in symbol.upper():
                    logging.info(f"‚ùå {symbol} rejected: {reason}")
                    return False
            
            symbol_upper = symbol.upper()
            for feature, reason in prohibited_features.items():
                if feature in symbol_upper:
                    logging.info(f"‚ùå {symbol} rejected: {reason}")
                    return False
            
            if symbol in approved_crypto:
                crypto_info = approved_crypto[symbol]
                logging.info(f"‚úÖ {symbol} approved: {crypto_info['reason']} "
                             f"(Risk: {crypto_info['risk_level']}, Utility: {crypto_info['utility_score']})")
                return True
            
            stablecoin_indicators = ['USDT', 'USDC', 'BUSD', 'DAI', 'TUSD']
            if any(indicator in symbol.upper() for indicator in stablecoin_indicators):
                if 'DAI' not in symbol.upper():
                    logging.info(f"‚úÖ {symbol} approved: Asset-backed stablecoin")
                    return True
                else:
                    logging.info(f"‚ùå {symbol} rejected: Algorithmic stablecoin with complex mechanisms")
                    return False
            
            logging.warning(f"‚ùå {symbol} rejected: Not in approved crypto list - requires manual review")
            return False
            
        except Exception as e:
            logging.error(f"Error in crypto halal screening for {symbol}: {e}")
            return False

class RiskManager:
    """Enhanced risk management with portfolio-level controls and dynamic adjustments"""
    
    def __init__(self, max_portfolio_risk=0.02, max_position_risk=0.01):
        self.max_portfolio_risk = max_portfolio_risk
        self.max_position_risk = max_position_risk
        self.position_tracker = {}
        self.risk_metrics = {}
        self.correlation_matrix = {}
        
        self.risk_models = {
            'conservative': {'portfolio_risk': 0.01, 'position_risk': 0.005, 'max_positions': 5},
            'moderate': {'portfolio_risk': 0.02, 'position_risk': 0.01, 'max_positions': 10},
            'aggressive': {'portfolio_risk': 0.03, 'position_risk': 0.015, 'max_positions': 15}
        }
        
        self.current_risk_model = 'moderate'
    
    def calculate_position_size(self, account_value: float, confidence: float,
                                  asset_config: AssetConfig, current_price: float,
                                  stop_loss: Optional[float] = None,
                                  portfolio_positions: Optional[Dict] = None) -> float:
        """Enhanced position sizing with portfolio-level risk management"""
        try:
            if account_value <= 0 or current_price <= 0 or confidence <= 0:
                return 0.0
            
            risk_params = self.risk_models[self.current_risk_model]
            
            base_position_pct = self._calculate_kelly_position(confidence, asset_config)
            
            confidence_adjusted_pct = base_position_pct * confidence
            
            max_single_position = min(
                asset_config.max_position_pct,
                risk_params['portfolio_risk'] / risk_params['position_risk']
            )
            
            risk_based_position_value = account_value
            
            if stop_loss and abs(current_price - stop_loss) > 0:
                risk_per_share = abs(current_price - stop_loss)
                max_risk_amount = account_value * risk_params['position_risk']
                max_shares_by_risk = max_risk_amount / risk_per_share
                risk_based_position_value = max_shares_by_risk * current_price
                
                logging.debug(f"Risk-based sizing: risk_per_share={risk_per_share:.4f}, "
                              f"max_risk_amount={max_risk_amount:.2f}, "
                              f"max_position_value={risk_based_position_value:.2f}")
            
            correlation_adjustment = self._calculate_correlation_adjustment(
                asset_config.symbol, portfolio_positions
            )
            
            volatility_adjustment = self._calculate_volatility_adjustment(asset_config, current_price)
            
            adjusted_position_pct = (confidence_adjusted_pct *
                                       correlation_adjustment *
                                       volatility_adjustment)
            
            position_value = min(
                account_value * adjusted_position_pct,
                account_value * max_single_position,
                risk_based_position_value
            )
            
            quantity = position_value / current_price
            
            if asset_config.is_crypto:
                quantity = round(max(quantity, asset_config.min_qty), asset_config.precision)
            else:
                quantity = max(int(quantity), int(asset_config.min_qty))
            
            final_position_value = quantity * current_price
            final_position_pct = final_position_value / account_value
            
            if final_position_pct > max_single_position:
                quantity = (account_value * max_single_position) / current_price
                if asset_config.is_crypto:
                    quantity = round(quantity, asset_config.precision)
                else:
                    quantity = int(quantity)
            
            logging.debug(f"Position sizing for {asset_config.symbol}: "
                          f"quantity={quantity:.6f}, value=${quantity * current_price:.2f}, "
                          f"pct={quantity * current_price / account_value:.2%}")
            
            return max(quantity, 0)
            
        except Exception as e:
            logging.error(f"Error calculating position size for {asset_config.symbol}: {e}")
            return 0.0
    
    def _calculate_kelly_position(self, confidence: float, asset_config: AssetConfig) -> float:
        """Calculate position size using modified Kelly Criterion"""
        try:
            win_probability = 0.5 + (confidence - 0.5) * 0.8
            
            if asset_config.is_crypto:
                avg_win = 0.05
                avg_loss = 0.03
            else:
                avg_win = 0.03
                avg_loss = 0.02
            
            b = avg_win / avg_loss
            p = win_probability
            q = 1 - p
            
            kelly_fraction = (b * p - q) / b
            
            conservative_kelly = max(0, kelly_fraction * 0.25)
            
            max_kelly = 0.15 if asset_config.is_crypto else 0.10
            
            return min(conservative_kelly, max_kelly)
            
        except Exception as e:
            logging.error(f"Error calculating Kelly position: {e}")
            return 0.05
    
    def _calculate_correlation_adjustment(self, symbol: str, 
                                             portfolio_positions: Optional[Dict]) -> float:
        """Calculate correlation adjustment to reduce portfolio concentration risk"""
        try:
            if not portfolio_positions:
                return 1.0
            
            correlation_penalty = 0.0
            
            for existing_symbol, position_info in portfolio_positions.items():
                if existing_symbol == symbol:
                    continue
                
                estimated_correlation = self._estimate_correlation(symbol, existing_symbol)
                position_weight = position_info.get('weight', 0.0)
                
                correlation_penalty += estimated_correlation * position_weight
            
            adjustment = max(0.5, 1.0 - correlation_penalty * 0.5)
            
            logging.debug(f"Correlation adjustment for {symbol}: {adjustment:.3f}")
            return adjustment
            
        except Exception as e:
            logging.error(f"Error calculating correlation adjustment: {e}")
            return 1.0
    
    def _estimate_correlation(self, symbol1: str, symbol2: str) -> float:
        """Estimate correlation between two assets"""
        try:
            if ('/' in symbol1 and '/' in symbol2):
                return 0.7
            
            if ('/' not in symbol1 and '/' not in symbol2):
                tech_stocks = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', 'NVDA']
                if symbol1 in tech_stocks and symbol2 in tech_stocks:
                    return 0.6
                else:
                    return 0.3
            
            return 0.2
            
        except Exception:
            return 0.3
    
    def _calculate_volatility_adjustment(self, asset_config: AssetConfig, current_price: float) -> float:
        """Calculate volatility-based position size adjustment"""
        try:
            if asset_config.is_crypto:
                base_volatility = 0.04
                if 'BTC' in asset_config.symbol:
                    estimated_volatility = base_volatility * 0.8
                elif any(coin in asset_config.symbol for coin in ['SOL', 'AVAX']):
                    estimated_volatility = base_volatility * 1.3
                else:
                    estimated_volatility = base_volatility
            else:
                base_volatility = 0.02
                if asset_config.symbol in ['TSLA', 'NVDA']:
                    estimated_volatility = base_volatility * 1.5
                else:
                    estimated_volatility = base_volatility
            
            volatility_adjustment = min(1.0, 0.02 / estimated_volatility)
            
            logging.debug(f"Volatility adjustment for {asset_config.symbol}: "
                          f"{volatility_adjustment:.3f} (est_vol={estimated_volatility:.3f})")
            
            return volatility_adjustment
            
        except Exception as e:
            logging.error(f"Error calculating volatility adjustment: {e}")
            return 1.0
    
    def update_risk_model(self, market_conditions: str = 'normal'):
        """Update risk model based on market conditions"""
        try:
            if market_conditions == 'high_volatility':
                self.current_risk_model = 'conservative'
                logging.info("üõ°Ô∏è Switched to conservative risk model due to high volatility")
            elif market_conditions == 'low_volatility':
                self.current_risk_model = 'aggressive'
                logging.info("üìà Switched to aggressive risk model due to low volatility")
            else:
                self.current_risk_model = 'moderate'
                logging.info("‚öñÔ∏è Using moderate risk model")
                
        except Exception as e:
            logging.error(f"Error updating risk model: {e}")
    
    def calculate_portfolio_risk(self, positions: Dict[str, Dict]) -> Dict[str, float]:
        """Calculate comprehensive portfolio risk metrics"""
        try:
            if not positions:
                return {'total_risk': 0.0, 'concentration_risk': 0.0, 'correlation_risk': 0.0}
            
            total_value = sum(pos['value'] for pos in positions.values())
            weights = {symbol: pos['value'] / total_value for symbol, pos in positions.items()}
            
            concentration_risk = sum(w**2 for w in weights.values())
            
            max_position_weight = max(weights.values()) if weights else 0
            
            correlation_risk = 0.0
            symbols = list(positions.keys())
            for i, symbol1 in enumerate(symbols):
                for symbol2 in symbols[i+1:]:
                    correlation = self._estimate_correlation(symbol1, symbol2)
                    weight_product = weights[symbol1] * weights[symbol2]
                    correlation_risk += correlation * weight_product
            
            return {
                'total_risk': concentration_risk + correlation_risk,
                'concentration_risk': concentration_risk,
                'correlation_risk': correlation_risk,
                'max_position_weight': max_position_weight,
                'number_of_positions': len(positions)
            }
            
        except Exception as e:
            logging.error(f"Error calculating portfolio risk: {e}")
            return {'total_risk': 0.0, 'concentration_risk': 0.0, 'correlation_risk': 0.0}


class EnhancedHalalTradingBot:
    """Main enhanced halal trading bot with comprehensive features and async support"""
    
    def __init__(self, config_file: str = "config.yaml", is_dry_run: bool = False):
        self.config = TradingConfig.from_yaml(config_file)
        
        self.connection_manager = ConnectionManager(self.config)
        self.notification_manager = NotificationManager(self.config)
        self.halal_screener = AdvancedHalalScreener(self.config)
        self.strategies = AdvancedTradingStrategies(self.config)
        self.trade_executor = EnhancedTradeExecutor(self.connection_manager, self.config, is_dry_run)
        self.risk_manager = RiskManager(
            max_portfolio_risk=self.config.max_portfolio_risk,
            max_position_risk=self.config.max_position_risk
        )
        
        self.session_results = {}
        self.performance_metrics = {}
        self.execution_stats = {
            'sessions_run': 0,
            'total_signals_generated': 0,
            'trades_executed': 0,
            'avg_session_duration': 0,
            'success_rate': 0.0
        }
        
        self.data_cache = {}
        self.cache_timestamps = {}
        
        logging.info("üïå Enhanced Halal Trading Bot v2.2 Initialized")
        logging.info(f"Configuration: {len(self.config.stock_universe)} stocks, "
                     f"{len(self.config.crypto_universe)} cryptos")
        logging.info(f"Risk Management: Portfolio={self.config.max_portfolio_risk:.1%}, "
                     f"Position={self.config.max_position_risk:.1%}")

    async def run_trading_session(self) -> Dict:
        """Run comprehensive trading session with enhanced features"""
        session_start = datetime.now()
        session_id = f"session_{session_start.strftime('%Y%m%d_%H%M%S')}"
        
        logging.info(f"üöÄ Starting enhanced trading session: {session_id}")
        
        try:
            health_status = await self.connection_manager.health_check()
            if not any(health_status.values()):
                logging.error("‚ùå No healthy API connections available")
                await self.notification_manager.send_error_alert(
                    "No healthy API connections available", "high"
                )
                return {}
            
            account_value = await self._get_account_value()
            if account_value <= 0:
                logging.error("‚ùå Cannot determine account value, aborting session")
                return {}
            
            logging.info(f"üí∞ Account Value: ${account_value:,.2f}")
            
            current_positions = await self._get_current_positions()
            portfolio_risk = self.risk_manager.calculate_portfolio_risk(current_positions)
            
            logging.info(f"üìä Portfolio Risk Metrics: "
                         f"Concentration={portfolio_risk['concentration_risk']:.3f}, "
                         f"Positions={portfolio_risk['number_of_positions']}")
            
            all_assets = ([(symbol, False) for symbol in self.config.stock_universe] + 
                          [(symbol, True) for symbol in self.config.crypto_universe])
            
            semaphore = asyncio.Semaphore(self.config.max_concurrent_assets)
            
            async def process_asset_with_semaphore(symbol, is_crypto):
                async with semaphore:
                    return await self._process_asset(symbol, is_crypto, account_value, current_positions)
            
            logging.info(f"üîÑ Processing {len(all_assets)} assets concurrently...")
            tasks = [process_asset_with_semaphore(symbol, is_crypto) 
                     for symbol, is_crypto in all_assets]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            successful_results = 0
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    symbol, is_crypto = all_assets[i]
                    logging.error(f"‚ùå Error processing {symbol}: {result}")
                else:
                    successful_results += 1
            
            logging.info(f"‚úÖ Successfully processed {successful_results}/{len(all_assets)} assets")
            
            self.execution_stats['sessions_run'] += 1
            self.execution_stats['total_signals_generated'] += len(self.session_results)
            
            session_duration = datetime.now() - session_start
            self.execution_stats['avg_session_duration'] = (
                (self.execution_stats['avg_session_duration'] * (self.execution_stats['sessions_run'] - 1) + 
                 session_duration.total_seconds()) / self.execution_stats['sessions_run']
            )
            
            report = self._generate_enhanced_session_report(session_duration, session_id)
            
            if self.config.enable_notifications:
                await self.notification_manager.send_summary_report(report)
            
            await self._save_session_results(session_id, self.session_results)
            
            logging.info(f"‚úÖ Trading session {session_id} completed in {session_duration}")
            
            return self.session_results
            
        except Exception as e:
            logging.error(f"‚ùå Trading session {session_id} failed: {e}")
            if self.config.enable_notifications:
                await self.notification_manager.send_error_alert(
                    f"Trading session failed: {str(e)}", "high"
                )
            return {}
        
        finally:
            try:
                await self._cleanup_session()
            except Exception as e:
                logging.error(f"Error during session cleanup: {e}")
    
    async def _process_asset(self, symbol: str, is_crypto: bool, account_value: float, 
                             current_positions: Dict) -> None:
        """Process individual asset with comprehensive analysis"""
        try:
            start_time = time.time()
            
            is_halal = await self._check_halal_compliance(symbol, is_crypto)
            if not is_halal:
                logging.debug(f"‚ùå {symbol} rejected: Not halal compliant")
                return
            
            df = await self._get_cached_market_data(symbol, is_crypto)
            if df is None or len(df) < self.config.min_data_points:
                logging.warning(f"‚ö†Ô∏è {symbol}: Insufficient data ({len(df) if df is not None else 0} points)")
                return
            
            indicators = await run_sync(self.strategies.ta.calculate_indicators)(df, symbol)
            if indicators.empty:
                logging.warning(f"‚ö†Ô∏è {symbol}: No indicators calculated")
                return
            
            signal = await self._execute_combined_strategy(symbol, df, indicators, is_crypto)
            
            if signal.action in ['buy', 'sell'] and signal.confidence > self.config.confidence_threshold:
                
                adaptive_threshold = self.strategies.get_adaptive_threshold(symbol)
                if signal.confidence < adaptive_threshold:
                    logging.debug(f"üîÑ {symbol}: Signal below adaptive threshold "
                                  f"({signal.confidence:.2f} < {adaptive_threshold:.2f})")
                    signal.action = 'hold'
                
                if signal.action != 'hold':
                    asset_config = self._get_asset_config(symbol, is_crypto)
                    position_size = self.risk_manager.calculate_position_size(
                        account_value, signal.confidence, asset_config,
                        df['close'].iloc[-1], signal.stop_loss, current_positions
                    )
                    
                    if position_size >= asset_config.min_qty:
                        execution = await self.trade_executor.execute_trade(
                            symbol, signal, position_size, is_crypto
                        )
                        
                        if execution:
                            self.execution_stats['trades_executed'] += 1
                            
                            if self.config.enable_notifications:
                                await self.notification_manager.send_trade_alert(
                                    signal, symbol, df['close'].iloc[-1]
                                )
                                
                            logging.info(f"‚úÖ Trade executed: {signal.action.upper()} "
                                         f"{position_size:.6f} {symbol} @ ${df['close'].iloc[-1]:.4f}")
                    else:
                        logging.debug(f"üìè {symbol}: Position size too small ({position_size:.6f})")
            
            processing_time = time.time() - start_time
            self.session_results[symbol] = {
                'signal': signal,
                'current_price': df['close'].iloc[-1],
                'is_crypto': is_crypto,
                'is_halal': is_halal,
                'timestamp': datetime.now(),
                'processing_time': processing_time,
                'data_points': len(df),
                'indicators_calculated': len(indicators.columns) if not indicators.empty else 0
            }
            
            logging.debug(f"‚ö° Processed {symbol} in {processing_time:.2f}s")
            
        except Exception as e:
            logging.error(f"‚ùå Error processing {symbol}: {e}")
            self.session_results[symbol] = {
                'signal': TradeSignal('hold', 0.0, 'error'),
                'current_price': 0.0,
                'is_crypto': is_crypto,
                'is_halal': False,
                'timestamp': datetime.now(),
                'error': str(e)
            }
    
    async def _check_halal_compliance(self, symbol: str, is_crypto: bool) -> bool:
        """Check halal compliance with caching"""
        try:
            cache_key = f"halal_{symbol}"
            
            if (cache_key in self.data_cache and 
                cache_key in self.cache_timestamps and
                datetime.now() - self.cache_timestamps[cache_key] < timedelta(hours=24)):
                return self.data_cache[cache_key]
            
            if is_crypto:
                is_halal = self.halal_screener.is_halal_crypto(symbol)
            else:
                screening_result = await self.halal_screener.comprehensive_screening(symbol)
                is_halal = screening_result['is_halal']
            
            self.data_cache[cache_key] = is_halal
            self.cache_timestamps[cache_key] = datetime.now()
            
            return is_halal
            
        except Exception as e:
            logging.error(f"Error checking halal compliance for {symbol}: {e}")
            return False
    
    async def _get_cached_market_data(self, symbol: str, is_crypto: bool) -> Optional[pd.DataFrame]:
        """Get market data with caching"""
        try:
            cache_key = f"data_{symbol}_{is_crypto}"
            
            if (cache_key in self.data_cache and 
                cache_key in self.cache_timestamps and
                datetime.now() - self.cache_timestamps[cache_key] < timedelta(hours=self.config.data_cache_hours)):
                logging.debug(f"Using cached data for {symbol}")
                return self.data_cache[cache_key]
            
            df = await self._get_market_data(symbol, is_crypto)
            
            if df is not None:
                self.data_cache[cache_key] = df
                self.cache_timestamps[cache_key] = datetime.now()
                
                if len(self.data_cache) > 100:
                    self._cleanup_cache()
            
            return df
            
        except Exception as e:
            logging.error(f"Error getting cached market data for {symbol}: {e}")
            return None
    
    async def _get_market_data(self, symbol: str, is_crypto: bool = False, 
                                  timeframe: str = '1h', limit: int = 200) -> Optional[pd.DataFrame]:
        """Enhanced market data retrieval with better error handling and validation"""
        try:
            if is_crypto and self.connection_manager.exchange:
                ohlcv = await self.connection_manager.execute_with_retry(
                    self.connection_manager.exchange.fetch_ohlcv,
                    symbol, timeframe, limit=limit
                )
                
                if not ohlcv:
                    logging.warning(f"No OHLCV data returned for {symbol}")
                    return None
                
                df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
                df.set_index('timestamp', inplace=True)
                
            elif not is_crypto and self.connection_manager.alpaca:
                timeframe_map = {'1h': '1Hour', '4h': '4Hour', '1d': '1Day'}
                alpaca_timeframe = timeframe_map.get(timeframe, '1Hour')
                
                end_time = datetime.now()
                start_time = end_time - timedelta(days=min(limit // 6, 365))
                
                bars = await self.connection_manager.execute_with_retry(
                    self.connection_manager.alpaca.get_bars,
                    symbol, alpaca_timeframe,
                    start=start_time.isoformat(),
                    end=end_time.isoformat(),
                    limit=limit
                )
                
                if bars.df.empty:
                    logging.warning(f"No bar data returned for {symbol}")
                    return None
                
                df = bars.df[['open', 'high', 'low', 'close', 'volume']].copy()
                
            else:
                logging.error(f"No appropriate API connection available for {symbol}")
                return None
            
            if len(df) < 10:
                logging.warning(f"Insufficient data for {symbol}: {len(df)} bars")
                return None
            
            df = df.dropna()
            
            if (df['close'] <= 0).any():
                logging.warning(f"Invalid price data detected for {symbol}")
                df = df[df['close'] > 0]
            
            price_median = df['close'].median()
            price_std = df['close'].std()
            outlier_threshold = 5 * price_std
            
            if price_std > 0:
                outliers = abs(df['close'] - price_median) > outlier_threshold
                if outliers.sum() > len(df) * 0.1:
                    logging.warning(f"High number of price outliers for {symbol}")
                else:
                    df = df[~outliers]
            
            if df['close'].isna().sum() > len(df) * 0.05:
                logging.warning(f"Poor data quality for {symbol}: {df['close'].isna().sum()} NaN values")
                return None
            
            if is_crypto and len(df) > 1:
                time_diff = df.index.to_series().diff().dt.total_seconds()
                expected_interval = 3600 if timeframe == '1h' else 86400
                
                if time_diff.max() > expected_interval * 2:
                    gap_count = (time_diff > expected_interval * 1.5).sum()
                    if gap_count > len(df) * 0.1:
                        logging.warning(f"Significant timestamp gaps in {symbol} data: {gap_count} gaps")
            
            if len(df) < self.config.min_data_points:
                logging.warning(f"Insufficient data after cleaning for {symbol}: {len(df)} < {self.config.min_data_points}")
                return None
            
            df = df.sort_index()
            
            logging.debug(f"‚úÖ Retrieved {len(df)} valid data points for {symbol}")
            return df
            
        except Exception as e:
            logging.error(f"Error fetching market data for {symbol}: {e}")
            return None
    
    def _cleanup_cache(self):
        """Clean up old cache entries"""
        try:
            current_time = datetime.now()
            expired_keys = [
                key for key, timestamp in self.cache_timestamps.items()
                if current_time - timestamp > timedelta(hours=self.config.data_cache_hours * 2)
            ]
            
            for key in expired_keys:
                self.data_cache.pop(key, None)
                self.cache_timestamps.pop(key, None)
            
            if len(self.data_cache) > 50:
                sorted_items = sorted(self.cache_timestamps.items(), key=lambda x: x[1])
                for key, _ in sorted_items[:20]:
                    self.data_cache.pop(key, None)
                    self.cache_timestamps.pop(key, None)
                    
        except Exception as e:
            logging.error(f"Error cleaning up cache: {e}")
    
    async def _get_account_value(self) -> float:
        """Get current account value with enhanced error handling"""
        try:
            if self.trade_executor.is_dry_run:
                return 100000.0 # Mock value for dry run
            
            if self.connection_manager.alpaca:
                account = await self.connection_manager.execute_with_retry(
                    self.connection_manager.alpaca.get_account
                )
                
                portfolio_value = float(account.portfolio_value)
                
                if portfolio_value <= 0:
                    logging.warning("Account portfolio value is zero or negative")
                    return 0.0
                
                logging.debug(f"Account Status: {account.status}, "
                              f"Buying Power: ${float(account.buying_power):,.2f}, "
                              f"Cash: ${float(account.cash):,.2f}")
                
                return portfolio_value
                
            else:
                logging.warning("No Alpaca connection available, using default account value")
                return 10000.0
                
        except Exception as e:
            logging.error(f"Error getting account value: {e}")
            return 0.0
    
    async def _get_current_positions(self) -> Dict[str, Dict]:
        """Get current portfolio positions for risk management"""
        try:
            positions = {}
            
            if self.trade_executor.is_dry_run:
                # Mock positions for dry run
                return {'MSFT': {'quantity': 10, 'value': 4500, 'weight': 0.045, 'unrealized_pnl': 500}}
            
            if self.connection_manager.alpaca:
                alpaca_positions = await self.connection_manager.execute_with_retry(
                    self.connection_manager.alpaca.list_positions
                )
                
                for position in alpaca_positions:
                    if float(position.qty) != 0:
                        positions[position.symbol] = {
                            'quantity': float(position.qty),
                            'value': float(position.market_value),
                            'weight': 0.0,
                            'unrealized_pnl': float(position.unrealized_pl)
                        }
            
            total_value = sum(pos['value'] for pos in positions.values())
            if total_value > 0:
                for pos in positions.values():
                    pos['weight'] = pos['value'] / total_value
            
            return positions
            
        except Exception as e:
            logging.error(f"Error getting current positions: {e}")
            return {}
    
    def _get_asset_config(self, symbol: str, is_crypto: bool) -> AssetConfig:
        """Enhanced asset configuration with dynamic parameters"""
        try:
            if is_crypto:
                if 'BTC' in symbol:
                    precision, min_qty = 6, 0.0001
                elif any(coin in symbol for coin in ['ETH', 'SOL', 'AVAX']):
                    precision, min_qty = 4, 0.001
                elif any(coin in symbol for coin in ['ADA', 'DOT', 'ALGO']):
                    precision, min_qty = 3, 0.01
                else:
                    precision, min_qty = 3, 0.01
            else:
                precision, min_qty = 0, 1.0
            
            if is_crypto:
                if 'BTC' in symbol:
                    strategy_weights = {
                        'mean_reversion': 0.4,
                        'ml_strategy': 0.35,
                        'momentum_breakout': 0.25
                    }
                elif 'SOL' in symbol or 'AVAX' in symbol:
                    strategy_weights = {
                        'momentum_breakout': 0.5,
                        'ml_strategy': 0.3,
                        'mean_reversion': 0.2
                    }
                elif any(coin in symbol for coin in ['ETH', 'ADA', 'DOT']):
                    strategy_weights = {
                        'ml_strategy': 0.4,
                        'momentum_breakout': 0.35,
                        'mean_reversion': 0.25
                    }
                else:
                    strategy_weights = {
                        'momentum_breakout': 0.5,
                        'ml_strategy': 0.3,
                        'mean_reversion': 0.2
                    }
            else:
                if symbol in ['TSLA', 'NVDA', 'META']:
                    strategy_weights = {
                        'momentum_breakout': 0.5,
                        'ml_strategy': 0.3,
                        'mean_reversion': 0.2
                    }
                elif symbol in ['AAPL', 'MSFT', 'GOOGL']:
                    strategy_weights = {
                        'ml_strategy': 0.4,
                        'mean_reversion': 0.35,
                        'momentum_breakout': 0.25
                    }
                elif symbol in ['JNJ', 'BRK.B', 'V']:
                    strategy_weights = {
                        'mean_reversion': 0.5,
                        'ml_strategy': 0.3,
                        'momentum_breakout': 0.2
                    }
                else:
                    strategy_weights = {
                        'mean_reversion': 0.4,
                        'ml_strategy': 0.35,
                        'momentum_breakout': 0.25
                    }
            
            base_max_position = self.config.max_position_pct
            if is_crypto:
                max_position_pct = base_max_position * 0.8
            else:
                max_position_pct = base_max_position
            
            return AssetConfig(
                symbol=symbol,
                is_crypto=is_crypto,
                precision=precision,
                min_qty=min_qty,
                max_position_pct=max_position_pct,
                strategy_weights=strategy_weights,
                volatility_threshold=0.04 if is_crypto else 0.02
            )
            
        except Exception as e:
            logging.error(f"Error creating asset config for {symbol}: {e}")
            return AssetConfig(symbol, is_crypto)

    async def _execute_combined_strategy(self, symbol: str, df: pd.DataFrame, 
                                         indicators: pd.DataFrame, is_crypto: bool) -> TradeSignal:
        """Execute combined trading strategy with enhanced error handling"""
        try:
            asset_config = self._get_asset_config(symbol, is_crypto)
            signals = []
            
            try:
                momentum_signal = await run_sync(self.strategies.momentum_breakout_strategy)(df, indicators, asset_config)
                signals.append(('momentum_breakout', momentum_signal))
            except Exception as e:
                logging.warning(f"Momentum strategy failed for {symbol}: {e}")
                signals.append(('momentum_breakout', TradeSignal('hold', 0.0, 'momentum_error')))
            
            try:
                mean_reversion_signal = await run_sync(self.strategies.mean_reversion_strategy)(df, indicators, asset_config)
                signals.append(('mean_reversion', mean_reversion_signal))
            except Exception as e:
                logging.warning(f"Mean reversion strategy failed for {symbol}: {e}")
                signals.append(('mean_reversion', TradeSignal('hold', 0.0, 'mean_reversion_error')))
            
            if self.strategies.ml and ML_AVAILABLE:
                try:
                    features, targets, feature_names = await run_sync(self.strategies.ml.prepare_enhanced_features)(df, indicators)
                    
                    if features is not None and len(features) > 0:
                        if self.strategies.ml.should_retrain(symbol, len(features)):
                            retrain_success = await run_sync(self.strategies.ml.train_enhanced_model)(features, targets, symbol)
                            if not retrain_success:
                                logging.warning(f"ML model retraining failed for {symbol}")
                        
                        ml_action, ml_confidence = await run_sync(self.strategies.ml.predict_enhanced)(features, symbol)
                        ml_signal = TradeSignal(ml_action, ml_confidence, 'ml_strategy')
                        signals.append(('ml_strategy', ml_signal))
                    else:
                        logging.debug(f"Insufficient ML features for {symbol}")
                        signals.append(('ml_strategy', TradeSignal('hold', 0.0, 'ml_insufficient_data')))
                        
                except Exception as e:
                    logging.warning(f"ML strategy failed for {symbol}: {e}")
                    signals.append(('ml_strategy', TradeSignal('hold', 0.0, 'ml_error')))
            
            combined_signal = self._combine_signals(signals, asset_config)
            
            combined_signal = self._apply_market_regime_filter(combined_signal, df, indicators)
            
            return combined_signal
            
        except Exception as e:
            logging.error(f"Error executing combined strategy for {symbol}: {e}")
            return TradeSignal('hold', 0.0, 'combined_strategy_error')
    
    def _combine_signals(self, signals: List[Tuple[str, TradeSignal]], 
                         asset_config: AssetConfig) -> TradeSignal:
        """Enhanced signal combination with error handling and validation"""
        try:
            if not signals:
                return TradeSignal('hold', 0.0, 'no_signals')
            
            valid_signals = [(name, signal) for name, signal in signals 
                             if not signal.strategy.endswith('_error')]
            
            if not valid_signals:
                logging.warning("All strategy signals failed, returning hold")
                return TradeSignal('hold', 0.0, 'all_strategies_failed')
            
            weights = asset_config.strategy_weights or self.config.default_strategy_weights
            
            total_weight = 0
            weighted_signal = 0
            signal_contributions = []
            
            for strategy_name, signal in valid_signals:
                weight = weights.get(strategy_name, 0.0)
                if weight > 0:
                    signal_value = 0
                    if signal.action == 'buy':
                        signal_value = signal.confidence
                    elif signal.action == 'sell':
                        signal_value = -signal.confidence
                    
                    contribution = signal_value * weight
                    weighted_signal += contribution
                    total_weight += weight
                    
                    signal_contributions.append({
                        'strategy': strategy_name,
                        'action': signal.action,
                        'confidence': signal.confidence,
                        'weight': weight,
                        'contribution': contribution
                    })
            
            if total_weight > 0:
                final_signal_value = weighted_signal / total_weight
            else:
                final_signal_value = 0
            
            abs_signal = abs(final_signal_value)
            
            buy_threshold = 0.25 if abs_signal > 0.6 else 0.3
            sell_threshold = -0.25 if abs_signal > 0.6 else -0.3
            
            if final_signal_value > buy_threshold:
                action = 'buy'
                confidence = min(0.95, abs_signal)
            elif final_signal_value < sell_threshold:
                action = 'sell'
                confidence = min(0.95, abs_signal)
            else:
                action = 'hold'
                confidence = abs_signal
            
            strongest_signal = max(valid_signals, key=lambda x: x[1].confidence)[1]
            
            price_target = strongest_signal.price_target
            stop_loss = strongest_signal.stop_loss
            
            combined_signal = TradeSignal(
                action=action,
                confidence=confidence,
                strategy='combined_enhanced',
                price_target=price_target,
                stop_loss=stop_loss
            )
            
            logging.debug(f"Enhanced signal combination for {asset_config.symbol}: "
                          f"Final={action}({confidence:.2f}), Weighted_value={final_signal_value:.3f}")
            
            for contribution in signal_contributions:
                logging.debug(f"  - {contribution['strategy']}: {contribution['action']} "
                              f"({contribution['confidence']:.2f} * {contribution['weight']:.2f} = "
                              f"{contribution['contribution']:.3f})")
            
            return combined_signal
            
        except Exception as e:
            logging.error(f"Error combining signals for {asset_config.symbol}: {e}")
            return TradeSignal('hold', 0.0, 'signal_combination_error')
    
    def _apply_market_regime_filter(self, signal: TradeSignal, df: pd.DataFrame, 
                                       indicators: pd.DataFrame) -> TradeSignal:
        """Apply market regime filter to adjust signal strength"""
        try:
            if len(df) < 20:
                return signal
            
            returns = df['close'].pct_change().dropna()
            current_vol = returns.rolling(20).std().iloc[-1] if len(returns) > 20 else 0.02
            long_term_vol = returns.rolling(100).std().iloc[-1] if len(returns) > 100 else 0.02
            
            vol_regime = current_vol / (long_term_vol + 1e-8)
            
            if 'sma_20' in indicators.columns and 'sma_50' in indicators.columns:
                sma_20 = indicators['sma_20'].iloc[-1]
                sma_50 = indicators['sma_50'].iloc[-1]
                trend_direction = 1 if sma_20 > sma_50 else -1
                trend_strength = abs(sma_20 - sma_50) / sma_50 if sma_50 > 0 else 0
            else:
                trend_direction = 0
                trend_strength = 0
            
            confidence_adjustment = 1.0
            
            if vol_regime > 2.0:
                confidence_adjustment *= 0.7
                logging.debug(f"High volatility regime detected, reducing confidence by 30%")
            
            elif vol_regime < 0.5:
                confidence_adjustment *= 1.1
                logging.debug(f"Low volatility regime detected, boosting confidence by 10%")
            
            if ((signal.action == 'buy' and trend_direction > 0) or 
                (signal.action == 'sell' and trend_direction < 0)):
                trend_bonus = min(0.15, trend_strength * 2)
                confidence_adjustment *= (1 + trend_bonus)
                logging.debug(f"Trend alignment bonus: +{trend_bonus:.2%}")
            
            adjusted_confidence = min(0.95, signal.confidence * confidence_adjustment)
            
            adjusted_signal = TradeSignal(
                action=signal.action,
                confidence=adjusted_confidence,
                strategy=f"{signal.strategy}_regime_adjusted",
                price_target=signal.price_target,
                stop_loss=signal.stop_loss
            )
            
            return adjusted_signal
            
        except Exception as e:
            logging.error(f"Error applying market regime filter: {e}")
            return signal

    async def _save_session_results(self, session_id: str, results: Dict):
        """Save session results to file"""
        try:
            results_dir = Path("results")
            results_dir.mkdir(exist_ok=True)
            
            results_file = results_dir / f"{session_id}.json"
            
            serializable_results = {}
            for symbol, result in results.items():
                serializable_results[symbol] = {
                    'signal': {
                        'action': result['signal'].action,
                        'confidence': result['signal'].confidence,
                        'strategy': result['signal'].strategy,
                        'price_target': result['signal'].price_target,
                        'stop_loss': result['signal'].stop_loss,
                        'timestamp': result['signal'].timestamp.isoformat()
                    },
                    'current_price': result['current_price'],
                    'is_crypto': result['is_crypto'],
                    'is_halal': result['is_halal'],
                    'timestamp': result['timestamp'].isoformat(),
                    'processing_time': result.get('processing_time', 0),
                    'data_points': result.get('data_points', 0),
                    'indicators_calculated': result.get('indicators_calculated', 0)
                }
            
            with open(results_file, 'w') as f:
                json.dump(serializable_results, f, indent=2)
                
            logging.info(f"üíæ Session results saved to {results_file}")
            
        except Exception as e:
            logging.error(f"Error saving session results: {e}")
    
    async def _cleanup_session(self):
        """Clean up session resources"""
        try:
            self.session_results.clear()
            
            if len(self.data_cache) > 200:
                self._cleanup_cache()
                
            logging.debug("üßπ Session cleanup completed")
            
        except Exception as e:
            logging.error(f"Error during session cleanup: {e}")
    
    def _generate_enhanced_session_report(self, session_duration: timedelta, session_id: str) -> str:
        """Generate comprehensive session report with enhanced metrics"""
        try:
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')
            
            report = f"""
üïå **ENHANCED HALAL TRADING SESSION REPORT**
üìÖ **Session ID**: {session_id}
üìÖ **Generated**: {timestamp}
‚è±Ô∏è **Duration**: {session_duration}

üìä **SESSION SUMMARY**
"""
            
            account_value = asyncio.run(self._get_account_value())
            if account_value > 0:
                report += f"üí∞ **Portfolio Value**: ${account_value:,.2f}\n"
            
            total_assets = len(self.session_results)
            buy_signals = sum(1 for r in self.session_results.values() if r['signal'].action == 'buy')
            sell_signals = sum(1 for r in self.session_results.values() if r['signal'].action == 'sell')
            hold_signals = total_assets - buy_signals - sell_signals
            
            report += f"üìà **Assets Analyzed**: {total_assets}\n"
            report += f"üü¢ **Buy Signals**: {buy_signals}\n"
            report += f"üî¥ **Sell Signals**: {sell_signals}\n"
            report += f"‚ö´ **Hold Signals**: {hold_signals}\n\n"
            
            if self.session_results:
                avg_processing_time = np.mean([r.get('processing_time', 0) for r in self.session_results.values()])
                total_data_points = sum(r.get('data_points', 0) for r in self.session_results.values())
                avg_confidence = np.mean([r['signal'].confidence for r in self.session_results.values()])
                
                report += f"‚ö° **Performance Metrics**\n"
                report += f"- Average Processing Time: {avg_processing_time:.2f}s per asset\n"
                report += f"- Total Data Points Analyzed: {total_data_points:,}\n"
                report += f"- Average Signal Confidence: {avg_confidence:.1%}\n\n"
            
            strategy_performance = {}
            for result in self.session_results.values():
                strategy = result['signal'].strategy
                if strategy not in strategy_performance:
                    strategy_performance[strategy] = {'count': 0, 'avg_confidence': 0, 'actions': {'buy': 0, 'sell': 0, 'hold': 0}}
                strategy_performance[strategy]['count'] += 1
                strategy_performance[strategy]['avg_confidence'] += result['signal'].confidence
                strategy_performance[strategy]['actions'][result['signal'].action] += 1
            
            if strategy_performance:
                report += "üéØ **STRATEGY PERFORMANCE**\n"
                for strategy, perf in strategy_performance.items():
                    avg_conf = perf['avg_confidence'] / perf['count']
                    actions = perf['actions']
                    report += f"- **{strategy}**: {perf['count']} signals, {avg_conf:.1%} avg confidence\n"
                    report += f"  - Buy: {actions['buy']}, Sell: {actions['sell']}, Hold: {actions['hold']}\n"
                report += "\n"
            
            top_signals = sorted(
                [(symbol, result) for symbol, result in self.session_results.items() 
                 if result['signal'].action in ['buy', 'sell']],
                key=lambda x: x[1]['signal'].confidence,
                reverse=True
            )[:5]
            
            if top_signals:
                report += "üèÜ **TOP SIGNALS**\n"
                for symbol, result in top_signals:
                    signal = result['signal']
                    price = result['current_price']
                    emoji = "üü¢" if signal.action == "buy" else "üî¥"
                    
                    report += f"{emoji} **{symbol}**: {signal.action.upper()} @ ${price:.4f}\n"
                    report += f"  - Confidence: {signal.confidence:.1%} ({signal.signal_strength})\n"
                    report += f"  - Strategy: {signal.strategy}\n"
                    report += f"  - Risk Level: {signal.risk_level}\n"
                    if signal.stop_loss:
                        report += f"  - Stop Loss: ${signal.stop_loss:.4f}\n"
                    if signal.price_target:
                        report += f"  - Target: ${signal.price_target:.4f}\n"
                report += "\n"
            
            report += "‚öñÔ∏è **RISK & COMPLIANCE**\n"
            halal_compliant = sum(1 for r in self.session_results.values() if r.get('is_halal', False))
            crypto_analyzed = sum(1 for r in self.session_results.values() if r.get('is_crypto', False))
            stocks_analyzed = total_assets - crypto_analyzed
            
            report += f"‚úÖ **Halal Compliant Assets**: {halal_compliant}/{total_assets} ({halal_compliant/total_assets:.1%})\n"
            report += f"ü™ô **Crypto Assets Analyzed**: {crypto_analyzed}\n"
            report += f"üìà **Stock Assets Analyzed**: {stocks_analyzed}\n"
            report += f"üõ°Ô∏è **Max Position Risk**: {self.config.max_position_risk:.1%}\n"
            report += f"üìä **Max Portfolio Risk**: {self.config.max_portfolio_risk:.1%}\n\n"
            
            executed_trades = self.execution_stats['trades_executed']
            if executed_trades > 0:
                report += f"‚ö° **EXECUTION SUMMARY**\n"
                report += f"- Trades Executed This Session: {len([r for r in self.session_results.values() if r['signal'].action in ['buy', 'sell']])}\n"
                report += f"- Total Trades Executed: {executed_trades}\n"
                report += f"- Total Sessions Run: {self.execution_stats['sessions_run']}\n"
                report += f"- Average Session Duration: {self.execution_stats['avg_session_duration']:.1f}s\n\n"
            
            if self.config.enable_performance_monitoring:
                report += "üîß **SYSTEM PERFORMANCE**\n"
                report += f"- Cache Hit Rate: {len(self.data_cache)} cached items\n"
                report += f"- Memory Usage: {len(self.session_results)} session results stored\n"
                report += f"- API Health: {asyncio.run(self._format_health_status())}\n\n"
            
            report += "‚ÑπÔ∏è **CONFIGURATION**\n"
            report += f"- Paper Trading: {'Enabled' if self.config.alpaca_paper_trading else 'Disabled'}\n"
            report += f"- ML Strategies: {'Enabled' if ML_AVAILABLE else 'Disabled'}\n"
            report += f"- Notifications: {'Enabled' if self.config.enable_notifications else 'Disabled'}\n"
            report += f"- Risk Model: {self.risk_manager.current_risk_model.title()}\n"
            report += f"- Concurrent Assets: {self.config.max_concurrent_assets}\n\n"
            
            report += "---\n*Enhanced Halal Trading Bot v2.2 - Automated Islamic Finance Compliance*"
            
            return report
            
        except Exception as e:
            logging.error(f"Error generating enhanced session report: {e}")
            return f"""
üïå **ENHANCED HALAL TRADING SESSION REPORT**
‚ùå **Error generating detailed report**: {e}
üìÖ **Timestamp**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}
‚è±Ô∏è **Session Duration**: {session_duration}

üìä **Basic Summary**
- Assets Processed: {len(self.session_results)}
- Session ID: {session_id}

*Please check logs for detailed information*
            """
    
    async def _format_health_status(self) -> str:
        """Format API health status for reporting"""
        try:
            health_status = await self.connection_manager.health_check()
            status_items = []
            
            for api, status in health_status.items():
                emoji = "‚úÖ" if status else "‚ùå"
                status_items.append(f"{api.title()}: {emoji}")
            
            return ", ".join(status_items)
            
        except Exception as e:
            return f"Health check failed: {e}"

# =============================================================================
# MAIN ENTRY POINTS AND CLI
# =============================================================================

async def run_live_trading(config_file: str, is_dry_run: bool):
    """Run live trading session with enhanced error handling"""
    try:
        bot = EnhancedHalalTradingBot(config_file, is_dry_run)
        
        # Ensure notifications are enabled for critical alerts
        bot.config.enable_notifications = True
        
        results = await bot.run_trading_session()
        
        if results:
            total_signals = len(results)
            buy_signals = sum(1 for r in results.values() if r['signal'].action == 'buy')
            sell_signals = sum(1 for r in results.values() if r['signal'].action == 'sell')
            hold_signals = total_signals - buy_signals - sell_signals
            
            logging.info(f"\nüïå Enhanced Halal Trading Session Complete!")
            logging.info(f"{'='*50}")
            logging.info(f"üìä Assets Analyzed: {total_signals}")
            logging.info(f"üü¢ Buy Signals: {buy_signals}")
            logging.info(f"üî¥ Sell Signals: {sell_signals}")
            logging.info(f"‚ö´ Hold Signals: {hold_signals}")
            
            top_signals = sorted(
                [(symbol, result) for symbol, result in results.items() 
                 if result['signal'].action in ['buy', 'sell']],
                key=lambda x: x[1]['signal'].confidence,
                reverse=True
            )[:5]
            
            if top_signals:
                logging.info(f"\nüèÜ Top Trading Signals:")
                logging.info(f"{'Symbol':<10} {'Action':<6} {'Confidence':<12} {'Strategy':<20} {'Price':<10}")
                logging.info(f"{'-'*70}")
                
                for symbol, result in top_signals:
                    signal = result['signal']
                    emoji = "üü¢" if signal.action == "buy" else "üî¥"
                    logging.info(f"{symbol:<10} {emoji} {signal.action.upper():<5} "
                          f"{signal.confidence:.1%}/<11} {signal.strategy:<20} "
                          f"${result['current_price']:.4f}")
            
            halal_assets = sum(1 for r in results.values() if r.get('is_halal', False))
            logging.info(f"\n‚öñÔ∏è Risk & Compliance Summary:")
            logging.info(f"‚úÖ Halal Compliant: {halal_assets}/{total_signals} ({halal_assets/total_signals:.1%})")
            
        else:
            logging.info("‚ùå No trading results generated")
        
        return results
        
    except KeyboardInterrupt:
        logging.warning("‚ö° Trading session interrupted by user")
        return {}
    except Exception as e:
        logging.error(f"‚ùå Live trading session failed: {e}")
        return {}

async def run_async_backtest(symbol: str, is_crypto: bool, config_file: str):
    """Run async backtesting analysis"""
    try:
        config = TradingConfig.from_yaml(config_file)
        
        connection_manager = ConnectionManager(config)
        bot = EnhancedHalalTradingBot(config_file)
        
        logging.info(f"üîç Starting enhanced backtest for {symbol} ({'crypto' if is_crypto else 'stock'})")
        
        df = await bot._get_market_data(symbol, is_crypto, limit=1000)
        
        if df is None or len(df) < 100:
            logging.error(f"‚ùå Insufficient data for {symbol}: {len(df) if df is not None else 0} bars")
            return None
        
        logging.info(f"üìä Retrieved {len(df)} data points for analysis")
        
        backtest_engine = EnhancedBacktestEngine(initial_capital=10000, config=config, strategies=bot.strategies)
        
        # This part should ideally be synchronous and would be run in executor
        # Or, the backtest engine itself needs to be refactored to be async-friendly
        results = await asyncio.get_event_loop().run_in_executor(
            None, backtest_engine.run_backtest, symbol, df, is_crypto
        )
        
        if results and 'performance_metrics' in results:
            metrics = results['performance_metrics']
            
            logging.info(f"\nüìà Enhanced Backtest Results for {symbol}")
            logging.info(f"{'='*60}")
            logging.info(f"Initial Capital:      ${results['initial_capital']:,.2f}")
            logging.info(f"Final Equity:         ${results['final_equity']:,.2f}")
            logging.info(f"Total Return:         {metrics.get('total_return', 0):.2%}")
            logging.info(f"Annualized Return:    {metrics.get('annualized_return', 0):.2%}")
            logging.info(f"Volatility:           {metrics.get('volatility', 0):.2%}")
            logging.info(f"Sharpe Ratio:         {metrics.get('sharpe_ratio', 0):.2f}")
            logging.info(f"Sortino Ratio:        {metrics.get('sortino_ratio', 0):.2f}")
            logging.info(f"Max Drawdown:         {metrics.get('max_drawdown', 0):.2%}")
            logging.info(f"Win Rate:             {metrics.get('win_rate', 0):.1%}")
            logging.info(f"Total Trades:         {results['total_trades']}")
            
            if results['total_trades'] > 0:
                logging.info(f"Profit Factor:        {metrics.get('profit_factor', 0):.2f}")
                logging.info(f"Avg Win:              {metrics.get('avg_win', 0):.2%}")
                logging.info(f"Avg Loss:             {metrics.get('avg_loss', 0):.2%}")
                
                total_fees = sum(trade.get('fees', 0) for trade in results.get('trades', []))
                logging.info(f"Total Fees:           ${total_fees:.2f}")
                
                if metrics.get('max_drawdown', 0) != 0:
                    calmar_ratio = metrics.get('annualized_return', 0) / abs(metrics.get('max_drawdown', 0.01))
                    logging.info(f"Calmar Ratio:         {calmar_ratio:.2f}")
        
        await connection_manager.close()
        
        return results
        
    except Exception as e:
        logging.error(f"Async backtest analysis failed for {symbol}: {e}")
        return None

async def run_async_halal_screening(symbols: List[str] = None, config_file: str = "config.yaml"):
    """Run async halal screening analysis"""
    try:
        config = TradingConfig.from_yaml(config_file)
        screener = AdvancedHalalScreener(config)
        
        if symbols is None:
            symbols = config.stock_universe + config.crypto_universe
        
        logging.info(f"üïå Enhanced Halal Compliance Screening Analysis")
        logging.info(f"{'='*70}")
        logging.info(f"Analyzing {len(symbols)} assets...")
        
        results = {}
        approved_count = 0
        
        semaphore = asyncio.Semaphore(5)
        
        async def screen_symbol(symbol):
            async with semaphore:
                try:
                    is_crypto = '/' in symbol or symbol.endswith('USDT')
                    
                    if is_crypto:
                        is_halal = screener.is_halal_crypto(symbol)
                        result = {
                            'is_halal': is_halal,
                            'compliance_score': 1.0 if is_halal else 0.0,
                            'asset_type': 'crypto',
                            'warnings': [] if is_halal else ['Not in approved crypto list, requires manual review.'],
                            'positive_factors': ['Utility-based cryptocurrency'] if is_halal else []
                        }
                    else:
                        result = await screener.comprehensive_screening(symbol)
                        result['asset_type'] = 'stock'
                    
                    return symbol, result
                    
                except Exception as e:
                    logging.error(f"Screening failed for {symbol}: {e}")
                    return symbol, {
                        'is_halal': False,
                        'compliance_score': 0.0,
                        'asset_type': 'unknown',
                        'warnings': [f'Screening error: {str(e)}'],
                        'positive_factors': []
                    }
        
        tasks = [screen_symbol(symbol) for symbol in symbols]
        screening_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        logging.info(f"\n{'Symbol':<12} {'Status':<12} {'Score':<8} {'Type':<8} {'Warnings':<20}")
        logging.info(f"{'-'*70}")
        
        for item in screening_results:
            if isinstance(item, Exception):
                logging.error(f"A task failed with exception: {item}")
                continue
                
            symbol, result = item
            results[symbol] = result
            
            if result['is_halal']:
                approved_count += 1
                status = "‚úÖ APPROVED"
                score_color = f"{result['compliance_score']:.1%}"
            else:
                status = "‚ùå REJECTED"
                score_color = f"{result['compliance_score']:.1%}"
            
            warnings_summary = f"{len(result.get('warnings', []))} issues" if result.get('warnings') else "None"
            
            logging.info(f"{symbol:<12} {status:<12} {score_color:<8} {result['asset_type']:<8} {warnings_summary:<20}")
            
            if result.get('warnings'):
                for warning in result['warnings'][:2]:
                    logging.info(f"   ‚ö†Ô∏è  {warning[:60]}...")
            
            if result.get('positive_factors'):
                for factor in result['positive_factors'][:1]:
                    logging.info(f"   ‚úÖ {factor[:60]}...")
        
        logging.info(f"\nüìä Enhanced Screening Summary:")
        logging.info(f"{'='*50}")
        logging.info(f"Total Assets Analyzed:      {len(symbols)}")
        logging.info(f"Approved for Investment:    {approved_count} ({approved_count/len(symbols):.1%})")
        logging.info(f"Rejected Assets:            {len(symbols) - approved_count}")
        
        crypto_approved = sum(1 for r in results.values() 
                              if r['asset_type'] == 'crypto' and r['is_halal'])
        crypto_total = sum(1 for r in results.values() if r['asset_type'] == 'crypto')
        stock_approved = sum(1 for r in results.values() 
                             if r['asset_type'] == 'stock' and r['is_halal'])
        stock_total = sum(1 for r in results.values() if r['asset_type'] == 'stock')
        
        if crypto_total > 0:
            logging.info(f"Crypto Approval Rate:       {crypto_approved}/{crypto_total} ({crypto_approved/crypto_total:.1%})")
        if stock_total > 0:
            logging.info(f"Stock Approval Rate:        {stock_approved}/{stock_total} ({stock_approved/stock_total:.1%})")
        
        avg_score = np.mean([r['compliance_score'] for r in results.values()])
        logging.info(f"Average Compliance Score:   {avg_score:.1%}")
        
        all_warnings = []
        for result in results.values():
            all_warnings.extend(result.get('warnings', []))
        
        if all_warnings:
            from collections import Counter
            common_warnings = Counter(all_warnings).most_common(3)
            logging.info(f"\nMost Common Issues:")
            for warning, count in common_warnings:
                logging.info(f"  ‚Ä¢ {warning} ({count} assets)")
        
        return results
        
    except Exception as e:
        logging.error(f"Halal screening analysis failed: {e}")
        return {}

async def run_self_test(config_file: str):
    """Run a diagnostic self-test to check connections and mock trade logic."""
    try:
        config = TradingConfig.from_yaml(config_file)
        
        logging.info("üî¨ Running Self-Test...")
        logging.info("=" * 30)
        
        # 1. API Health Check
        connection_manager = ConnectionManager(config)
        health_status = await connection_manager.health_check()
        logging.info("\nü©∫ API Health Check:")
        for api, status in health_status.items():
            emoji = "‚úÖ" if status else "‚ùå"
            logging.info(f"- {api.title()}: {emoji}")
        
        # 2. Mock Trading Test
        logging.info("\nü§ñ Mock Trading Simulation:")
        mock_bot = EnhancedHalalTradingBot(config_file, is_dry_run=True)
        mock_asset = 'AAPL'
        mock_is_crypto = False
        mock_account_value = 50000.0
        
        # Mock data for the test
        mock_df = pd.DataFrame({
            'open': [150] * 100, 'high': [155] * 100, 'low': [148] * 100, 
            'close': [152] * 100, 'volume': [1000] * 100
        }, index=pd.date_range(end=datetime.now(), periods=100, freq='H'))
        mock_df.loc[mock_df.index[-1], 'close'] = 160  # Simulate a breakout
        
        mock_indicators = await run_sync(mock_bot.strategies.ta.calculate_indicators)(mock_df, mock_asset)
        
        mock_signal = mock_bot._execute_combined_strategy(mock_asset, mock_df, mock_indicators, mock_is_crypto)
        
        if mock_signal.action == 'buy' and mock_signal.confidence > 0.5:
            logging.info(f"‚úÖ Mock signal generated successfully: {mock_signal.action} with confidence {mock_signal.confidence:.2f}")
            mock_asset_config = mock_bot._get_asset_config(mock_asset, mock_is_crypto)
            mock_position_size = mock_bot.risk_manager.calculate_position_size(
                mock_account_value, mock_signal.confidence, mock_asset_config,
                mock_df['close'].iloc[-1], mock_signal.stop_loss
            )
            logging.info(f"‚úÖ Mock position size calculated: {mock_position_size:.2f} shares")
        else:
            logging.warning(f"‚ùå Mock trade logic failed to generate a strong signal. Got: {mock_signal.action} (conf={mock_signal.confidence:.2f})")
        
        await connection_manager.close()
        logging.info("\n‚úÖ Self-Test Complete!")
        return True
    except Exception as e:
        logging.error(f"‚ùå Self-Test Failed: {e}")
        return False

def main():
    """Enhanced main application entry point with comprehensive CLI"""
    
    parser = argparse.ArgumentParser(
        description="Enhanced Halal Trading Bot v2.2 - Islamic Finance Compliant Automated Trading",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python tradingbot.py --mode live                 # Run live trading session
  python tradingbot.py --mode live --dry-run       # Run a simulated live trading session
  python tradingbot.py --mode backtest --symbol AAPL      # Backtest Apple stock
  python tradingbot.py --mode backtest --symbol BTC/USDT --crypto # Backtest Bitcoin
  python tradingbot.py --mode screen               # Screen all configured assets
  python tradingbot.py --mode screen --symbol TSLA       # Screen specific symbol
  python tradingbot.py --mode test                 # Run the unittest suite
  python tradingbot.py --mode health               # Check API connection health
  python tradingbot.py --mode selftest             # Run a diagnostic self-test
  
CLI Flags:
  --mode (live, backtest, screen, test, health, selftest):
    Sets the primary function of the script.
    - `live`: Runs a live trading session.
    - `backtest`: Runs a backtest for a specific symbol.
    - `screen`: Performs halal compliance screening.
    - `test`: Runs the standard unittest test suite.
    - `health`: Performs a quick check on API connections.
    - `selftest`: Runs a diagnostic test of connections and core logic.

  --symbol (str):
    Specifies the asset symbol to be used for `backtest` or `screen` mode.
    E.g., `AAPL`, `BTC/USDT`.

  --config (str, default='config.yaml'):
    Specifies the path to the YAML configuration file.

  --crypto:
    Used with `--symbol` to explicitly treat the asset as a cryptocurrency,
    overriding the automatic detection based on '/' or 'USDT' in the symbol.

  --stock:
    Used with `--symbol` to explicitly treat the asset as a stock, overriding
    the automatic detection.

  --verbose, -v:
    Enables verbose logging (DEBUG level) for detailed output.

  --dry-run:
    Forces `live` mode to run in a simulation state. No real trades will be executed.

  --no-notifications:
    Temporarily disables all notifications for the current run, regardless
    of the `config.yaml` setting.

Environment Variables Required (typically in a .env file):
  ALPACA_API_KEY, ALPACA_SECRET_KEY    - Alpaca trading API credentials
  BINANCE_API_KEY, BINANCE_SECRET_KEY  - Binance crypto API credentials (optional)
  TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID - Telegram notifications (optional)
  NOTIFICATION_EMAIL, EMAIL_PASSWORD   - Email notifications (optional)
        """
    )
    
    parser.add_argument('--mode', 
                        choices=['live', 'backtest', 'screen', 'test', 'health', 'selftest'], 
                        default='live', 
                        help='Operation mode (default: live)')
    
    parser.add_argument('--symbol', type=str, 
                        help='Symbol for backtesting or screening')
    
    parser.add_argument('--config', type=str, default='config.yaml', 
                        help='Configuration file path (default: config.yaml)')
    
    parser.add_argument('--crypto', action='store_true', 
                        help='Force treat symbol as cryptocurrency')
    
    parser.add_argument('--stock', action='store_true', 
                        help='Force treat symbol as stock')
    
    parser.add_argument('--verbose', '-v', action='store_true',
                        help='Enable verbose logging')
    
    parser.add_argument('--dry-run', action='store_true',
                        help='Run in simulation mode without executing trades')
    
    parser.add_argument('--no-notifications', action='store_true',
                        help='Disable all notifications')
    
    args = parser.parse_args()
    
    log_level = 'DEBUG' if args.verbose else 'INFO'
    setup_logging(log_level)
    
    if args.no_notifications:
        try:
            config = TradingConfig.from_yaml(args.config)
            config.enable_notifications = False
            config.save_to_yaml(args.config)
            logging.info("Notifications disabled for this run.")
        except Exception as e:
            logging.error(f"Failed to disable notifications in config file: {e}")
            
    try:
        if args.mode == 'live':
            config = TradingConfig.from_yaml(args.config)
            print_startup_summary(args, config)
            asyncio.run(run_live_trading(args.config, args.dry_run))
            
        elif args.mode == 'backtest':
            if not args.symbol:
                logging.error("‚ùå Symbol required for backtest mode. Use --symbol SYMBOL")
                sys.exit(1)
            
            is_crypto = None
            if args.crypto:
                is_crypto = True
            elif args.stock:
                is_crypto = False
            else:
                is_crypto = '/' in args.symbol or args.symbol.endswith('USDT')
            
            asyncio.run(run_async_backtest(args.symbol, is_crypto, args.config))
                
        elif args.mode == 'screen':
            config = TradingConfig.from_yaml(args.config)
            print_startup_summary(args, config)
            symbols = [args.symbol] if args.symbol else None
            asyncio.run(run_async_halal_screening(symbols, args.config))
                
        elif args.mode == 'health':
            config = TradingConfig.from_yaml(args.config)
            print_startup_summary(args, config)
            connection_manager = ConnectionManager(config)
            
            async def health_check_run():
                health_status = await connection_manager.health_check()
                logging.info(f"\nüìä System Health Status:")
                logging.info(f"=" * 30)
                
                for api, status in health_status.items():
                    emoji = "‚úÖ" if status else "‚ùå"
                    logging.info(f"{api.title()}: {emoji}")
                
                overall_health = any(health_status.values())
                logging.info(f"\nOverall System Health: {'‚úÖ HEALTHY' if overall_health else '‚ùå DEGRADED'}")
                
                await connection_manager.close()
            
            asyncio.run(health_check_run())

        elif args.mode == 'selftest':
            config = TradingConfig.from_yaml(args.config)
            print_startup_summary(args, config)
            asyncio.run(run_self_test(args.config))
            
        elif args.mode == 'test':
            logging.info("üß™ Running Enhanced Test Suite")
            logging.info("=" * 40)
            
            loader = unittest.TestLoader()
            suite = loader.discover('.', pattern='test_*.py')
            runner = unittest.TextTestRunner(verbosity=2)
            result = runner.run(suite)
            
            if result.wasSuccessful():
                logging.info(f"\n‚úÖ All tests passed!")
            else:
                logging.error(f"\n‚ùå {len(result.failures)} test(s) failed, {len(result.errors)} error(s)")
                sys.exit(1)
    
    except KeyboardInterrupt:
        logging.warning("\n‚ö° Operation cancelled by user")
        sys.exit(0)
        
    except Exception as e:
        # Get the config to send an alert
        try:
            config_for_alert = TradingConfig.from_yaml(args.config)
            alert_manager = NotificationManager(config_for_alert)
            asyncio.run(alert_manager.send_error_alert(
                f"A critical application error occurred: {e}", "critical"
            ))
        except Exception as alert_e:
            logging.error(f"Failed to send critical error alert: {alert_e}")
            
        logging.critical(f"\n‚ùå A critical application error occurred: {e}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main()
